/*  Copyright 2011-2013 Alexis Herault, Giuseppe Bilotta, Robert A. Dalrymple, Eugenio Rustico, Ciro Del Negro

    Istituto Nazionale di Geofisica e Vulcanologia
        Sezione di Catania, Catania, Italy

    Università di Catania, Catania, Italy

    Johns Hopkins University, Baltimore, MD

    This file is part of GPUSPH.

    GPUSPH is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    GPUSPH is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with GPUSPH.  If not, see <http://www.gnu.org/licenses/>.
*/

#ifndef _FORCES_KERNEL_AUX
#define _FORCES_KERNEL_AUX

/// This file defines the heavy-duty forcesDevice kernel (at the end).
/// The kernel itself is now quite streamlined, and it only contains sequences
/// of calls to templatized functors that do the actual job according to their
/// specialization (based on SPH formulation, boundary type, viscosity type, etc).
/// The functors themselves operate on sets of data structures which are also
/// templatized based on the same parameters, and that include only the
/// variables actually needed for each specialization.

/// Some hints:
/// * const-ify everything that can be made const
/// * if the initialization of a would-be const member is complex, define an
///   auxiliary function for it
/// * functors use the 'with' operator. Both the functors and their operators
///   may be templatized, as a way to circumvent the limits on partial template
///   specializations imposed by C++
/// * the kernel params, particle data, neighbor data etc are also complex templatized
///   structures; you can work around this when having to declare the arguments to
///   the functor operators by using generic typenames FP, P, N, OP, ON
///   (for Forces Params, Particle, Neighbor, Output for Particle, Output from Neighbor)

/// The file is thus structured:
/// * a set of auxiliary functions, which are used later on to initialize
///   const members of structures in one go; these are needed
/// * particle data structures and output variables
/// * neighbor data structures and output variables
/// * functors for the computation of forces contributions
/// * functors for post-processing and saving
/// * global (shared) variables and their functors
/// * the actual forcesDevice kernel

/*
 * Auxiliary functions, needed to initialize const members in one go
 */

/// Precompute pressure contribution to the momemntum equation.
/// Two versions are available, one in the KEPS viscosity case,
/// and a generic one

// Generic:
template<SPHFormulation sph_formulation>
__device__ __forceinline__
float
precalc_pressure(const float rho, particleinfo const& info);

/* when using SPH formulation 1, the precomputed pressure contribution
   for the current particle is p/rho^2 */
template<>
__device__ __forceinline__
float
precalc_pressure<SPH_F1>(const float rho, particleinfo const& info)
{
	return P(rho, PART_FLUID_NUM(info))/(rho*rho);
}

/* when using SPH formulation 2, the precomputed pressure contribution
   for the current particle is just p */
template<>
__device__ __forceinline__
float
precalc_pressure<SPH_F2>(const float rho, particleinfo const& info)
{
	return P(rho, PART_FLUID_NUM(info));
}

// With KEPS visc:
template<SPHFormulation sph_formulation>
__device__ __forceinline__
float
precalc_pressure(const float rho, particleinfo const& info, const float keps_k);

// in case of k-e model we use p~ = p + 2/3*rho*k
// the remaining implementation is the same as in the generic case
template<>
__device__ __forceinline__
float
precalc_pressure<SPH_F1>(const float rho, particleinfo const& info, const float keps_k)
{
	return (P(rho, PART_FLUID_NUM(info)) + 2.0f*keps_k/rho/3.0f)/(rho*rho);
}

template<>
__device__ __forceinline__
float
precalc_pressure<SPH_F2>(const float rho, particleinfo const& info, const float keps_k)
{
	return P(rho, PART_FLUID_NUM(info)) + 2.0f*keps_k/rho/3.0f;
}

/*
 * Particle data
 */

// The amount and type of particle data retrieved for the current particle
// being processed and for the neighbor particle depend on a variety of factors,
// including SPH formulation, boundary type, viscosity etc, but also the
// particle type (fluid, object, boundary, vertex). We use a conditional struct
// assembly mechanism similar to the one seen in src/forces_params.h

// data used for all particles
struct common_particle_data
{
	const	uint	index;
	particleinfo	const& info;
	float4	const&	pos;
	const	int3	gridPos;

	__device__ __forceinline__
	common_particle_data(const uint _index, float4 const& _pos, particleinfo const& _info, hashKey const* hash) :
		index(_index),
		info(_info),
		pos(_pos),
		gridPos(calcGridPosFromParticleHash(hash[index]))
	{}
};

// data used only for objects
struct rb_particle_data
{
	const	uint	rbindex;

	__device__ __forceinline__
	rb_particle_data(particleinfo const& info) : rbindex(id(info) + d_rbstartindex[object(info)])
	{}
};

// velocity. used for:
// * fluid particles
// * vertex particles if KEPSVISC
struct vel_particle_data
{
	const	float4	vel;

	__device__ __forceinline__
	vel_particle_data(const uint index) : vel(tex1Dfetch(velTex, index))
	{}
};

// speed of sound
// used only for dyndt, ARTVISC or SA_BOUNDARY
struct sspeed_particle_data
{
	const	float	sspeed;

	__device__ __forceinline__
	sspeed_particle_data(const float rho, particleinfo const& info) :
		sspeed(soundSpeed(rho, PART_FLUID_NUM(info)))
	{}
};

// data used for SA_BOUNDARY
template<ViscosityType visctype>
struct sa_boundary_particle_data
{
	// does this particle want to (re)compute gamma? see logic below
	// this is used by vertex particles only
	bool	computeGamma;

	// oldGGam would hold the previous value of gamma (in .w) and its gradient (in .xyz).
	// oldGGam is used in case of vertex particles to compute the solid angle of vertex particles.
	// For fluid particles it is used in case the particle is too close to a wall
	const	float4	oldGGam;

	// For fluid particles, we always want to recompute gamma, while for vertex
	// particles we only want to recompute if we have moving boundaries or if
	// gamma itself has not been computed before, where ‘computed before’ is
	// assessed by checking if its value is less than the given epsilon

	// fluid init
	__device__ __forceinline__
	sa_boundary_particle_data(const uint index, particleinfo const& info,
		sa_boundary_forces_params const& params) :
		computeGamma(FLUID(info) || (VERTEX(info) && (params.movingBoundaries || visctype==KEPSVISC))),
		// the actual oldGGam loading: this will also set computeGamma true if
		// it was false but .w was < epsilon
		oldGGam(fetchOldGamma(index, params.epsilon, computeGamma))
	{}
};

// SPSVISC particle data
struct sps_particle_data
{
	const	symtensor3	tau;

	__device__ __forceinline__
	sps_particle_data(const uint index) : tau(fetchTau(index))
	{}
};

// KEPSVISC particle data
struct keps_particle_data
{
	// turbulent kinetic energy
	const	float	keps_k;
	// turbulent dissipation
	const	float	keps_e;
	// turbulent viscosity
	const	float	turbVisc;
	// turbulent viscosity for viscous term
	// this is 0 for vertex particles
	const	float	turbViscForViscTerm;

	__device__ __forceinline__
	keps_particle_data(const uint index, particleinfo const& info) :
		keps_k(tex1Dfetch(keps_kTex, index)),
		keps_e( tex1Dfetch(keps_eTex, index)),
		turbVisc(0.09f*keps_k*keps_k/fmax(keps_e, 1e-6f)),
		turbViscForViscTerm(FLUID(info) ? turbVisc : 0)
	{}
};

// Precomputed pressure contribution
// Automatic initialization of this beast is a bit messy because
// (1) we want it to be const
// (2) the initialization depends on SPH formulation and viscosity type
// (3) with KEPSVISC it needs one additional parameter
// (4) the value passed to the additional parameter only exists in the KEPSVISC case
// so the caller must be able to feed the last parameter correctly if it exsists,
// but not even try to provide it otherwise.
// The solution is to make this a templatized structure based on
// SPH formulation, plus the typename of an additional parameter, which
// will be the structure containing keps_k in the case of KEPSVISC.
// Suggestions for a better solution are welcome
template<SPHFormulation sph_formulation, typename T>
struct p_precalc_particle_data
{
	const	float	p_precalc;

	// default initializer, extra param is ignored
	__device__ __forceinline__
	p_precalc_particle_data(const float rho, particleinfo const& info, T const&) :
		p_precalc(precalc_pressure<sph_formulation>(rho, info))
	{}
};

// specialize the initializer
template<SPHFormulation sph_formulation>
struct p_precalc_particle_data<sph_formulation, keps_particle_data>
{
	const	float	p_precalc;

	__device__ __forceinline__
	p_precalc_particle_data(const float rho, particleinfo const& info, keps_particle_data const& ke) :
		p_precalc(precalc_pressure<sph_formulation>(rho, info, ke.keps_k))
	{}
};

// KEPSVISC precalc data, used only for fluid particles
// again, turbVisc should only be actually accessed by the caller if we are with KEPSVISC,
// so we assume the caller passes us a full keps_particle_data structure
// (which they will only do in the KEPSVISC case)
struct keps_precalc_particle_data
{
	const	float	dkdt_precalc;
	const	float	dedt_precalc;

	__device__ __forceinline__
	keps_precalc_particle_data(const float rho, keps_particle_data const& ke) :
		dkdt_precalc(rho*(d_visccoeff + ke.turbVisc)),
		dedt_precalc(rho*(d_visccoeff + ke.turbVisc/1.3f))
	{}
};

// And now we assemble them. Not all particle types require all particle data,
// but for the time being we don't optimize this far and just limit ourselves
// to conditional inclusions based on kernel specialization only, not particle type

template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	BoundaryType boundarytype,
	ViscosityType visctype,
	bool dyndt, bool usexsph>
struct forces_particle_data :
	// included unconditionally for all particles:
	common_particle_data,
	// the next is only needed for PT_OBJECT, which in fact need no other data
	rb_particle_data,
	// vel included unconditionally for all particles, even though
	// PT_VERTEX only use them for KEPSVISC, and
	// PT_OBJECT don't use them
	vel_particle_data,
	// SA_BOUNDARY data (always needed by PT_VERTEX, since they only obviously
	// appear with SA_BOUNDARY)
	COND_STRUCT(boundarytype == SA_BOUNDARY,
		sa_boundary_particle_data<visctype>),
	// KEPSVISC data, needed by both PT_FLUID and PT_VERTEX
	COND_STRUCT(visctype == KEPSVISC,
		keps_particle_data),
	// everything else is just for PT_FLUID
	COND_STRUCT(visctype == SPSVISC,
		sps_particle_data),
	COND_STRUCT(dyndt || (visctype == ARTVISC) || (boundarytype == SA_BOUNDARY),
		sspeed_particle_data),
	// to see why this is so messy, see definition of p_precalc_particle_data
	p_precalc_particle_data<sph_formulation,
		typename COND_STRUCT(visctype == KEPSVISC, keps_particle_data)>,
	COND_STRUCT(visctype == KEPSVISC,
		keps_precalc_particle_data)
{
	// shorthand for the type of the forces params
	typedef forces_params<kerneltype, boundarytype, visctype, dyndt, usexsph> params_t;

	ParticleType	ptype;

	// determine specialization automatically based on info and params
	__device__ __forceinline__
	forces_particle_data(const uint _index, float4 const& _pos, particleinfo const& _info,
		params_t const& params) :
		common_particle_data(_index, _pos, _info, params.particleHash),
		rb_particle_data(_info),
		vel_particle_data(_index),
		COND_STRUCT(boundarytype == SA_BOUNDARY,
			sa_boundary_particle_data<visctype>)(_index, _info, params),
		COND_STRUCT(visctype == KEPSVISC,
			keps_particle_data)(_index, _info),
		COND_STRUCT(visctype == SPSVISC,
			sps_particle_data)(_index),
		COND_STRUCT(dyndt || (visctype == ARTVISC) || (boundarytype == SA_BOUNDARY),
			sspeed_particle_data)(vel.w, _info),
		p_precalc_particle_data<sph_formulation,
			typename COND_STRUCT(visctype == KEPSVISC, keps_particle_data)>(vel.w, _info, *this),
		COND_STRUCT(visctype == KEPSVISC, keps_precalc_particle_data)(vel.w, *this),
		ptype(static_cast<ParticleType>PART_TYPE(_info))
	{}
};

/// Similarly for the output variables

// common
struct common_particle_output
{
	float4	force;
	float2	contupd;

	__device__ __forceinline__
	common_particle_output() :
		force(make_float4(0.0f)),
		contupd(make_float2(0.0f))
	{}
};

// SA_BOUNDARY
struct sa_boundary_particle_output
{
	// x,y,z contains the gradient of gamma, w gamma itself
	float4	gGam;
	// this is used to identify cases in which the normal gamma computation becomes singular
	// minimum distance between wall segments and the particle
	float minlRas;
	// alpha
	float alpha;
	// avg gam
	float gamavg;

	__device__ __forceinline__
	sa_boundary_particle_output() :
		gGam(make_float4(0, 0, 0, 1)),
		minlRas(1e10),
		alpha(0.0f),
		gamavg(0.0f)
	{}
};

// KEPSVISC
struct keps_particle_output
{
	float3	dvx;
	float3	dvy;
	float3	dvz;

	float	diff_term_k;
	float	diff_term_e;
	float	ce2yap;

	__device__ __forceinline__
	keps_particle_output()
	{
		dvx = dvy = dvz = make_float3(0.0f);
		diff_term_k = diff_term_e = 0;
		ce2yap = 1.92;
	}
};

// XSPH
struct xsph_particle_output
{
	float3	mean_vel;

	__device__ __forceinline__
	xsph_particle_output() : mean_vel(make_float3(0.0f))
	{}
};

template<BoundaryType boundarytype,
	ViscosityType visctype,
	bool usexsph>
struct forces_particle_output :
	common_particle_output,
	// TODO FIXME KEPSVISC currently depends on SA_BOUNDARY (see .e.g viscous_fixup<KEPSVISC>),
	// but there is no way to prevent it from being selected with other boundary conditions.
	// When this is implemented, the || visctype == KEPSVISC should be removed
	COND_STRUCT(boundarytype == SA_BOUNDARY || visctype == KEPSVISC, sa_boundary_particle_output),
	COND_STRUCT(visctype == KEPSVISC, keps_particle_output),
	COND_STRUCT(usexsph, xsph_particle_output)
{
	__device__ __forceinline__
	forces_particle_output() :
		common_particle_output(),
		// TODO FIXME see above
		COND_STRUCT(boundarytype == SA_BOUNDARY || visctype == KEPSVISC, sa_boundary_particle_output)(),
		COND_STRUCT(visctype == KEPSVISC, keps_particle_output)(),
		COND_STRUCT(usexsph, xsph_particle_output)()
	{}
};

/*
 * Neib data
 */

// Just like for particle data, we collect neib data into appropriate structures

// data used fo all neibs
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	BoundaryType boundarytype,
	ViscosityType visctype,
	bool dyndt, bool usexsph>
struct common_neib_data
{
	// we will get as arguments also the current particle data and forces_kernel params.
	// Define shorthands for their data type
	typedef forces_particle_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph> pdata_t;
	typedef forces_params<kerneltype, boundarytype, visctype, dyndt, usexsph> params_t;

	particleinfo	const& info;
	// relPos holds the distance vector in .xyz and the neib mass in .w
	float4	const&	relPos;
	const	float	r;

	// relVel holds the relative velocity in .xyz and the neib density in .w
	const	float4	relVel;
	const	float	vel_dot_pos;
	const	float	f;

	__device__ __forceinline__
	common_neib_data(pdata_t const& pdata, params_t const& params,
		const uint _index, particleinfo const& _info,
		float4 const& _relPos, const float _r) :
		info(_info), relPos(_relPos), r(_r),
		relVel(as_float3(pdata.vel) - tex1Dfetch(velTex, _index)),
		vel_dot_pos(dot3(relVel, relPos)),
		f(F<kerneltype>(r, params.slength))
	{}
};

template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	BoundaryType boundarytype,
	ViscosityType visctype,
	bool dyndt, bool usexsph>
struct sa_boundary_neib_data
{
	// we will get as arguments also the current particle data and forces_kernel params.
	// Define shorthands for their data type
	typedef forces_particle_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph> pdata_t;
	typedef forces_params<kerneltype, boundarytype, visctype, dyndt, usexsph> params_t;
	typedef forces_particle_output<SA_BOUNDARY, visctype, usexsph> pout_t;

	const uint index;

	const	float4	belem;
	const	float3&	normal_s;
	// distance of particle to boundary element along the normal
	const	float	r_as; // r_as as used by ptype == PT_FLUID, r_es as used by ptype == PT_VERTEX

	__device__ __forceinline__
	sa_boundary_neib_data(pdata_t const& pdata,  params_t const& params,
		const uint _index, float4 const& _relPos) :
		index(_index),
		belem(tex1Dfetch(boundTex, index)),
		normal_s(as_float3(belem)),
		r_as(fmax(fabs(dot(as_float3(_relPos), normal_s)), params.deltap))
	{}
};

template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	BoundaryType boundarytype,
	ViscosityType visctype,
	bool dyndt, bool usexsph>
struct forces_neib_data :
	common_neib_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph>,
// can't use COND_STRUCT here because of the commas in the sa_boundary_neib_data template def
	conditional<boundarytype == SA_BOUNDARY,
		sa_boundary_neib_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph>,
		empty<
			sa_boundary_neib_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph>
		> >::type,
	// these are the same as the particle data
	COND_STRUCT(visctype == KEPSVISC, keps_particle_data),
	// precalculated pressure
	p_precalc_particle_data<sph_formulation,
		typename COND_STRUCT(visctype == KEPSVISC, keps_particle_data)>,
	COND_STRUCT(visctype == SPSVISC, sps_particle_data),
	COND_STRUCT(boundarytype == SA_BOUNDARY || visctype == ARTVISC, sspeed_particle_data)
{
	// shortcut typedefs
	typedef common_neib_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph> _common_neib_data;
	typedef
		typename conditional<boundarytype == SA_BOUNDARY,
			sa_boundary_neib_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph>,
			empty<
				sa_boundary_neib_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph>
			> >::type
		_sa_boundary_neib_data;
	typedef typename _common_neib_data::pdata_t pdata_t;
	typedef typename _common_neib_data::params_t params_t;

	ParticleType	ntype;

	__device__ __forceinline__
	forces_neib_data(pdata_t const& pdata, params_t const& params,
		const uint _index, particleinfo const& _info,
		float4 const& _relPos, const float _r) :
		_common_neib_data(pdata, params, _index, _info, _relPos, _r),
		_sa_boundary_neib_data(pdata, params, _index, _relPos),
		COND_STRUCT(visctype == KEPSVISC, keps_particle_data)(_index, _info),
		p_precalc_particle_data<sph_formulation,
			typename COND_STRUCT(visctype == KEPSVISC, keps_particle_data)>(this->relVel.w, _info, *this),
		COND_STRUCT(visctype == SPSVISC, sps_particle_data)(_index),
		COND_STRUCT(boundarytype == SA_BOUNDARY || visctype == ARTVISC, sspeed_particle_data)(this->relVel.w, _info),
		ntype(static_cast<ParticleType>PART_TYPE(_info))
	{}
};

/// And finally the neib contribution to the current particle forces
struct common_neib_output
{
	// acceleration
	float3	DvDt;
	// density derivative
	float	DrDt;
	float	contDiff;
	float	DgamDt;

	__device__ __forceinline__
	common_neib_output() :
		DvDt(make_float3(0.0f)),
		DrDt(0.0f),
		contDiff(0.0f),
		DgamDt(0.0f)
	{}
};

struct sa_boundary_neib_output
{
	// gamAS as used by ptype == PT_FLUID, gamES as used by ptype == PT_VERTEX
	float2	gamAS;

	__device__ __forceinline__
	sa_boundary_neib_output() : gamAS(make_float2(0))
	{ }
};

template<BoundaryType boundarytype>
struct forces_neib_output :
	common_neib_output,
	COND_STRUCT(boundarytype == SA_BOUNDARY, sa_boundary_neib_output)
{
	__device__ __forceinline__
	forces_neib_output() :
		common_neib_output(),
		COND_STRUCT(boundarytype == SA_BOUNDARY, sa_boundary_neib_output)()
	{}
};

/*
 * A lot of parts of the forces kernel behave very differently based on some template parameters.
 * We isolate this behavior in template functions defined (and specialized) here.
 * TODO FIXME the syntax of these functors could be OH SO MUCH CLEANER if we could use C++11 ...
 */

/// The next set of functions check  if the given particle (pdata) should skip
/// traversing the neib list, and define the actions to be taken when skipping.
/// Since we need partial specialization, they cannot be actual functions.
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	BoundaryType boundarytype,
	ViscosityType visctype,
	bool dyndt, bool usexsph>
struct skip_neiblist
{
	// typedefs to shorten argument types
	typedef forces_particle_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph> pdata_t;
	typedef forces_particle_output<boundarytype, visctype, usexsph> pout_t;

	/// check if the given particle must skip the neiblist traversal
	__device__ __forceinline__
	bool check(pdata_t const& pdata)
	{
		return false; // default, don't skip
	}

	/// do anything that is needed to actually skip the neiblist traversal
	__device__ __forceinline__
	void prepare(pdata_t const& pdata, pout_t &pout)
	{ /* do nothing by default */ }

};

template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	ViscosityType visctype,
	bool dyndt, bool usexsph>
struct skip_neiblist<kerneltype, sph_formulation, SA_BOUNDARY, visctype, dyndt, usexsph>
{
	// typedefs to shorten argument types
	typedef forces_particle_data<kerneltype, sph_formulation, SA_BOUNDARY, visctype, dyndt, usexsph> pdata_t;
	typedef forces_particle_output<SA_BOUNDARY, visctype, usexsph> pout_t;

	__device__ __forceinline__
	bool check(pdata_t const& pdata)
	{
		// vertex particles will skip neighbors unless they need to compute gamma,
		// or when using KEPSVISC
		return visctype != KEPSVISC && (pdata.ptype == PT_VERTEX) && !pdata.computeGamma;
	}

	__device__ __forceinline__
	void prepare(pdata_t const& pdata, pout_t &pout)
	{
		// FIXME currently we can expect it to be a vertex particle, and this is what
		// we need to do, but in the future there might be other cases too
		pout.gGam = pdata.oldGGam;
	}
};

/*
 * Functors to compute neighbor contributions. Template structs with a single
 * static method (`with`) which takes params, pdata, ndata as const& input,
 * and pout, nout as & output. The method may also return something.
 * The method should be a template method based on the typenames of its arguments
 * (which would otherwise be too complex to specify, and it's not even necessary
 *  since template functions auto-match their arguments), so any specialization
 * based on the struct template parameter(s) will have two template<> specifications:
 * the first one for the struct, and the second (unchanged from the declaration)
 * for the method.
 */

/// A functor that computes the new gamma. Obviously does something
/// only in the case of SA_BOUNDARY
template<BoundaryType>
struct compute_gamma {
	template<KernelType kerneltype, typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{ /* do nothing */ }
};

template<>
template<KernelType kerneltype, typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
compute_gamma<SA_BOUNDARY>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	if (pdata.ptype != PT_OBJECT && (ndata.ntype == PT_VERTEX ) ) {
		const float4 neib_gam = tex1Dfetch(gamTex, ndata.index);
		const float dotRGG = 0.5f*dot3(neib_gam+pdata.oldGGam, ndata.relPos);
		const float ndist = fabs(dotRGG)/length3(0.5f*(neib_gam+pdata.oldGGam))/params.slength;
		const float wVol = ndata.r < params.slength ? 1.0f/max(ndist,1e-3f) : 0.0f;//W<kerneltype>(ndata.r, params.slength);
		pout.gamavg += (neib_gam.w + dotRGG)*wVol;
		pout.alpha += wVol;
	}
	// we do not compute gamma for OBJECT particles,
	// and only BOUNDARY particles contribute to it
	if (pdata.ptype != PT_OBJECT && ndata.ntype == PT_BOUNDARY) {
		nout.gamAS = Gamma<kerneltype>(params.slength, ndata.relPos,
				params.vertPos0[ndata.index], params.vertPos1[ndata.index], params.vertPos2[ndata.index],
				ndata.belem, pdata.oldGGam,
				params.epsilon, params.deltap, pdata.computeGamma, ndata.index,
				pout.minlRas);
		pout.gGam.x += nout.gamAS.x*ndata.belem.x;
		pout.gGam.y += nout.gamAS.x*ndata.belem.y;
		pout.gGam.z += nout.gamAS.x*ndata.belem.z;
		pout.gGam.w -= nout.gamAS.y;
	}
}

/// A functor that computes the time derivative of rho
template<BoundaryType>
struct compute_density_derivative {

	// common volumic Ferrari diffusion term
	// TODO the Ferrari correction should be handled based on its own template
	// parameter (use_ferrari or whatever).
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	ferrari_correction(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{
		const int fType =  PART_FLUID_NUM(pdata.info);
		// gravity correction for free-surface flows
		const float grav_corr = -dot(d_gravity, as_float3(ndata.relPos))*d_rho0[fType]/d_sqC0[fType];
		// actual diffusion term
		// TODO should use pdata.sspeed, ndata.sspeed, which should therefore be defined when use_ferrari is enabled
		const float3 ferraricor = (ndata.r > 1e-4f*params.slength) ?
			max(pdata.sspeed, ndata.sspeed)*
			(pdata.vel.w - ndata.relVel.w + grav_corr)/pdata.vel.w/ndata.r*as_float3(ndata.relPos) :
			make_float3(0.0f);
		// adding term to D\rho/Dt, weighted with d_ferrari (choose according to Mayrhofer et al. 2013, CPC)
		nout.contDiff += d_ferrari*ndata.relPos.w*dot(ferraricor, as_float3(ndata.relPos))*ndata.f;
	}

	// auxiliary function, which is used as fallback also in the SA_BOUNDARY case
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	common_with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{
		nout.DrDt = ndata.relPos.w*ndata.vel_dot_pos*ndata.f;
	}

	// actual method
	template<SPHFormulation sph_formulation,
		typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{
		common_with(params, pdata, ndata, pout, nout);
		// TODO this should not be done at runtime, but as a template option
		if (d_ferrari) {
			// volumic term of Ferrari diffusion term (according to Mayrhofer et al. 2013, CPC)
			ferrari_correction(params, pdata, ndata, pout, nout);
		}
		/* The second formulation takes into consideration the density ratio */
		if (sph_formulation == SPH_F2)
			nout.DrDt *= pdata.vel.w/ndata.relVel.w;
	}
};

/// Specialization in the SA_BOUNDARY case

template<>
template<SPHFormulation sph_formulation, typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
compute_density_derivative<SA_BOUNDARY>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	if (ndata.ntype == PT_BOUNDARY) {
		// boundary term of div(v)
		// AM-TODO assume no movement of i/o wall
		nout.DgamDt = dot3(pdata.vel, ndata.belem)*nout.gamAS.x;
		nout.DrDt = -ndata.relVel.w*dot3(ndata.relVel-pdata.vel, ndata.belem)*nout.gamAS.x;
		// AM-TODO this is for all pressure outlets
		// D\rho/Dn is not zero near a pressure outlet so the volume diffusion formula gains a term
		if (d_ferrari && object(ndata.info) == 2) {
			const int fType =  PART_FLUID_NUM(pdata.info);
			// gravity correction for free-surface flows
			const float grav_corr = -dot(d_gravity, as_float3(ndata.relPos))*d_rho0[fType]/d_sqC0[fType];
			// actual diffusion term
			const float ferraricor = max(pdata.sspeed, ndata.sspeed)*(pdata.vel.w - ndata.relVel.w + grav_corr);
			// adding term to D\rho/Dt, weighted with d_ferrari (choose according to Mayrhofer et al. 2013, CPC)
			nout.contDiff -= 2.0f*d_ferrari*ferraricor*nout.gamAS.x;
		}
	} else {
		// volumic term of div(v)
		common_with(params, pdata, ndata, pout, nout);
		if (d_ferrari) {
			// volumic term of Ferrari diffusion term (according to Mayrhofer et al. 2013, CPC)
			ferrari_correction(params, pdata, ndata, pout, nout);
		}
		/* The second formulation takes into consideration the density ratio */
		if (sph_formulation == SPH_F2) {
			nout.DrDt *= pdata.vel.w/ndata.relVel.w;
			nout.contDiff *= pdata.vel.w/ndata.relVel.w;
		}
	}

}

/// Functor to compute the pressure contribution to the particle acceleration.
/// The results should be stored in nout.DvDt
template<BoundaryType>
struct compute_pressure_contrib
{
	// auxiliary function, which is used as fallback also in the SA_BOUNDARY case
	// responsible for the volumic term, note that p_precalc can contain 2/3 \rho k if KEPSVISC is chosen
	template<SPHFormulation sph_formulation, typename FP, typename P_t, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static float
	common_with(FP const& params, P_t const& pdata, N const& ndata, OP &pout, ON &nout)
	{
		float pGradTerm = 0.0f;
		switch (sph_formulation) {
		case SPH_F1:
			pGradTerm = pdata.p_precalc + ndata.p_precalc;
			break;
		case SPH_F2:
			pGradTerm = (pdata.p_precalc + ndata.p_precalc)/(pdata.vel.w*ndata.relVel.w);
			break;
		}
		return pGradTerm;
	}

	// actual method to compute the full pressure gradient in the non SA_BOUNDARY case
	template<SPHFormulation sph_formulation,
		typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{
		const float pGradTerm(common_with<sph_formulation>(params, pdata, ndata, pout, nout));
		nout.DvDt -= pGradTerm*ndata.relPos.w*ndata.f*as_float3(ndata.relPos);
	}
};

/// Specialization in the SA_BOUNDARY case to add boundary terms
template<>
template<SPHFormulation sph_formulation,
	typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
compute_pressure_contrib<SA_BOUNDARY>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	// general pressure term
	const float pGradTerm(common_with<sph_formulation>(params, pdata, ndata, pout, nout));
	if (ndata.ntype == PT_BOUNDARY) {
		// full boundary term
		nout.DvDt += pGradTerm*ndata.relVel.w*nout.gamAS.x*ndata.normal_s;
	}
	else {
		// full volumic term
		nout.DvDt -= pGradTerm*ndata.relPos.w*ndata.f*as_float3(ndata.relPos);
	}
}

/// A functor that computes the mean velocity (XSPH)
template<bool usexsph>
struct compute_mean_vel
{
	template<KernelType kerneltype, typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{ /* do nothing */ }
};

template<>
template<KernelType kerneltype, typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
compute_mean_vel<true>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	pout.mean_vel -= ndata.relPos.w*W<kerneltype>(ndata.r, params.slength)*as_float3(ndata.relVel)/(pdata.vel.w + ndata.relVel.w);
}


/// A functor that computes simple fluid/boundary forces (LJ, MK)
template<BoundaryType>
struct compute_repulsive_force {
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout);
};

template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
compute_repulsive_force<LJ_BOUNDARY>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	nout.DvDt = LJForce(ndata.r)*as_float3(ndata.relPos);
}

template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
compute_repulsive_force<MK_BOUNDARY>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	nout.DvDt = MKForce(ndata.r, params.slength, pdata.pos.w, pdata.pos.w)*as_float3(ndata.relPos);
}

/// TODO FIXME currently this code path only computes the force between fluid particles and
/// non-BOUNDARY, non-VERTEX particles in the SA_BOUNDARY case: specifically, this computes
/// the interaction between FLUID and OBJECT particles when SA_BOUNDARY is active. Since
/// OBJECT particles currently assume LJ-style behavior, we use here LJ-style behavior.
/// This should
/// be fixed by:
/// (1) never mixing SA and non-SA boundary-type particles, and
/// (2) removing this special case
template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
compute_repulsive_force<SA_BOUNDARY>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	// TODO FIXME see above
	nout.DvDt = LJForce(ndata.r)*as_float3(ndata.relPos);
}

// auxiliary functor computing boundary contribution to the viscous term
// note that these boundary contributions are specialized for SA_BOUNDARY.
// As no other boundary condition has any boundary terms there is no need to add another template parameter
template<ViscosityType visctype>
struct visc_boundary_part {
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{}
};

template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
visc_boundary_part<DYNAMICVISC>::with
(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	// velocity of fluid particle along the wall
	const float3 vel_tau = as_float3(ndata.relVel) - dot(as_float3(ndata.relVel), ndata.normal_s)*ndata.normal_s;

	nout.DvDt -= nout.gamAS.x*d_visccoeff*(pdata.vel.w + ndata.relVel.w)/ndata.r_as*vel_tau/pdata.vel.w;
}

template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
visc_boundary_part<KEPSVISC>::with
(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	// a component of fluid paricle velocity tangential to the wall
	// TODO movingboundary: instead of pdata.vel use relative lagrangian velocity
	const float3 u_t = as_float3(pdata.vel) - dot(as_float3(pdata.vel), ndata.normal_s)*ndata.normal_s;
	const float abs_u_t = length(u_t);

	// we solve iteratively the wall law equation to obtain y+ value
	float u_star = 0.0f;
	// the constant is equal to 0.09^0.25
	const float uk = 0.547722558f*sqrt(pdata.keps_k);
	float y_plus = ndata.r_as/d_visccoeff*uk;
	// constant is equal to 1/0.41
	if(y_plus < 2.43902439f) // viscous sublayer
		u_star = abs_u_t/y_plus;
	else{ // log law
		// constant is equal to exp(-5.2*0.41)
		float utau = 0.118599857f*d_visccoeff/ndata.r_as;
		for (int i=0; i<10; i++) {
			// constant is equal to 1/0.41
			y_plus = fmax(ndata.r_as*utau/d_visccoeff, 2.43902439f);
			// constant is equal to 5.2*0.41+1
			utau = (0.41f*abs_u_t + utau)/(log(y_plus) + 3.132f);
		}
		u_star = abs_u_t / (log(y_plus)/0.41f + 5.2f);
	}

	nout.DvDt -= 2.0f*nout.gamAS.x*u_star*u_star*u_t/fmax(abs_u_t,1e-6f);
}

// auxiliary functor computing volumic contribution to the viscous term
template<ViscosityType visctype>
struct visc_volumic_part {
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout);
};

template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
visc_volumic_part<DYNAMICVISC>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	const float visc(laminarvisc_dynamic(pdata.vel.w, ndata.relVel.w, ndata.relPos.w, ndata.f,
		d_visccoeff*pdata.vel.w, d_visccoeff*ndata.relVel.w));
	nout.DvDt += visc*as_float3(ndata.relVel);
}

template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
visc_volumic_part<KINEMATICVISC>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	const float visc(laminarvisc_kinematic(pdata.vel.w, ndata.relVel.w, ndata.relPos.w, ndata.f));
	nout.DvDt += visc*as_float3(ndata.relVel);
}

// SPS viscosity is just kinematic + a contribution based on the strain rate
template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
visc_volumic_part<SPSVISC>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	nout.DvDt.x += ndata.relPos.w*ndata.f*(
		(pdata.tau.xx + ndata.tau.xx)*ndata.relPos.x +
		(pdata.tau.xy + ndata.tau.xy)*ndata.relPos.y +
		(pdata.tau.xz + ndata.tau.xz)*ndata.relPos.z);
	nout.DvDt.y += ndata.relPos.w*ndata.f*(
		(pdata.tau.xy + ndata.tau.xy)*ndata.relPos.x +
		(pdata.tau.yy + ndata.tau.yy)*ndata.relPos.y +
		(pdata.tau.yz + ndata.tau.yz)*ndata.relPos.z);
	nout.DvDt.z += ndata.relPos.w*ndata.f*(
		(pdata.tau.xz + ndata.tau.xz)*ndata.relPos.x +
		(pdata.tau.yz + ndata.tau.yz)*ndata.relPos.y +
		(pdata.tau.zz + ndata.tau.zz)*ndata.relPos.z);
	const float visc(laminarvisc_kinematic(pdata.vel.w, ndata.relVel.w, ndata.relPos.w, ndata.f));
	nout.DvDt += visc*as_float3(ndata.relVel);
}

// k-e viscosity: dynamic + turbulent
template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
visc_volumic_part<KEPSVISC>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	const float visc(laminarvisc_dynamic(pdata.vel.w, ndata.relVel.w, ndata.relPos.w, ndata.f,
		(d_visccoeff+pdata.turbViscForViscTerm)*pdata.vel.w,
		(d_visccoeff+ndata.turbViscForViscTerm)*ndata.relVel.w));
	nout.DvDt += visc*as_float3(ndata.relVel);
}

// artificial viscosity
template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
visc_volumic_part<ARTVISC>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	if (ndata.vel_dot_pos < 0.0f){
		const float visc = artvisc(ndata.vel_dot_pos, pdata.vel.w, ndata.relVel.w,
			pdata.sspeed, ndata.sspeed, ndata.r, params.slength);
		// note that here we use the position difference and not the velocity difference
		nout.DvDt += visc*as_float3(ndata.relPos)*ndata.relPos.w*ndata.f;
	}
}

/// A functor that computes the scalar viscous coefficient (plus additional optional contributions
/// directly to nout.
/// See above about the double template<> in the specializations
template<BoundaryType>
struct compute_viscous_contrib {

	template<ViscosityType visctype, typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout){
		// in the generic case only the volumic term is of interest
		visc_volumic_part<visctype>::with(params, pdata, ndata, pout, nout);
	}

};

template<>
template<ViscosityType visctype, typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
compute_viscous_contrib<SA_BOUNDARY>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	if (ndata.ntype == PT_BOUNDARY)
		// boundary term of the viscous part based on a boundary segment
		visc_boundary_part<visctype>::with(params, pdata, ndata, pout, nout);
	else
		// volumic term of the viscous part using vertices and fluid particles (same as in the generic case)
		visc_volumic_part<visctype>::with(params, pdata, ndata, pout, nout);
}

/// Functor to compute the KEPS diffusion and velocity gradient terms

template<BoundaryType boundarytype, ViscosityType visctype>
struct compute_keps_term
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{ /* do nothing */ }
};

template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
compute_keps_term<SA_BOUNDARY, KEPSVISC>::with
(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	float3 dvmul = make_float3(0.0f);

	// diffusion terms for k and epsilon, to be divided later by rho_a and gamma_a
	if (ndata.ntype == PT_BOUNDARY) {

		// yap correction
		// constant is 0.09^0.75/0.41
		const float lyap = 0.400772603f*powf(pdata.keps_k,1.5f)/(pdata.keps_e*ndata.r_as);
		if (lyap > 1.0f)
			pout.ce2yap = fmin(pout.ce2yap, fmax(1.92f - 0.83f*(lyap-1.0f)*lyap*lyap, 0.0f));

		// boundary contribution to epsilon diffusion term
		// the constant factor is 4.0f*0.09/1.3 where 0.09 = C_\mu and 1.3 = \sigma_\epsilon
		pout.diff_term_e += 0.276923077f*pdata.keps_k*pdata.keps_k/ndata.r_as*nout.gamAS.x;

		// multiplication for velocity gradient terms (gradGam_as*rho_s)
		dvmul = nout.gamAS.x*ndata.normal_s*ndata.relVel.w;

	} else if (ndata.ntype == PT_VERTEX || ndata.ntype == PT_FLUID) {

		// volume contribution for k and epsilon diffusion terms
		pout.diff_term_k += ndata.relPos.w*(
			pdata.dkdt_precalc + ndata.relVel.w*(d_visccoeff + ndata.turbVisc)
			)*(pdata.keps_k - ndata.keps_k)*ndata.f/ndata.relVel.w;
		pout.diff_term_e += ndata.relPos.w*(
			pdata.dedt_precalc + ndata.relVel.w*(d_visccoeff + ndata.turbVisc/1.3f)
			)*(pdata.keps_e - ndata.keps_e)*ndata.f/ndata.relVel.w;

		// multiplication for velocity gradient terms (- m_b*r_ab*gradW)
		dvmul = -ndata.relPos.w*as_float3(ndata.relPos)*ndata.f ;
	}

	// velocity gradient
	// From boundary:
	//	dvx = ∑ρs vxas ∇ɣas
	//	dvy = ∑ρs vyas ∇ɣas
	//	dvz = ∑ρs vzas ∇ɣas
	// From fluid/vertex:
	//	dvx = -∑mb vxab ∇(ra - rb)/r ∂Wab/∂r
	//	dvy = -∑mb vyab ∇(ra - rb)/r ∂Wab/∂r
	//	dvz = -∑mb vzab ∇(ra - rb)/r ∂Wab/∂r

	pout.dvx += ndata.relVel.x*dvmul;
	pout.dvy += ndata.relVel.y*dvmul;
	pout.dvz += ndata.relVel.z*dvmul;
}


/*
 * Post-processing and saving
 */


/// The next set of functors post-process the particle forces and write them to
/// the appropriate given arrays


/// A functor that does viscosity-related post-processing, and returns a
/// viscous coefficient to be used with DEMs and planes

template<ViscosityType>
struct viscous_fixup
{
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__
	static float
	with(FP const& params, P const& pdata, OP &pout);
};

/// Specializations

template<>
template<typename FP, typename P, typename OP >
__device__ __forceinline__ float
viscous_fixup<DYNAMICVISC>::with(FP const& params, P const& pdata, OP &pout)
{ return d_visccoeff*pdata.vel.w; }

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ float
viscous_fixup<KINEMATICVISC>::with(FP const& params, P const& pdata, OP &pout)
{ return d_visccoeff*pdata.vel.w/4; } // TODO FIXME check?

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ float
viscous_fixup<SPSVISC>::with(FP const& params, P const& pdata, OP &pout)
{ return d_visccoeff*pdata.vel.w/4; } // TODO FIXME check?

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ float
viscous_fixup<ARTVISC>::with(FP const& params, P const& pdata, OP &pout)
{ return 0; } // assumes free-slip

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ float
viscous_fixup<KEPSVISC>::with(FP const& params, P const& pdata, OP &pout)
{
	// final division for diff and dv{x,y,z} terms
	const float rhoGam = pdata.vel.w*pout.gGam.w;
	// finalize diffusion terms
	pout.diff_term_k /= rhoGam;
	pout.diff_term_e /= rhoGam;
	// finalize velocity gradients
	pout.dvx /= rhoGam;	// dvx = -1/ɣa*ρa ∑mb vxab (ra - rb)/r ∂Wab/∂r
	pout.dvy /= rhoGam;	// dvy = -1/ɣa*ρa ∑mb vyab (ra - rb)/r ∂Wab/∂r
	pout.dvz /= rhoGam;	// dvz = -1/ɣa*ρa ∑mb vzab (ra - rb)/r ∂Wab/∂r
	// Calculate norm of the mean strain rate tensor
	float SijSij_bytwo = 2.0f*(pout.dvx.x*pout.dvx.x +
		pout.dvy.y*pout.dvy.y +
		pout.dvz.z*pout.dvz.z);	// 2*SijSij = 2.0((∂vx/∂x)^2 + (∂vy/∂yx)^2 + (∂vz/∂z)^2)
	float temp = pout.dvx.y + pout.dvy.x;
	SijSij_bytwo += temp*temp;		// 2*SijSij += (∂vx/∂y + ∂vy/∂x)^2
	temp = pout.dvx.z + pout.dvz.x;
	SijSij_bytwo += temp*temp;		// 2*SijSij += (∂vx/∂z + ∂vz/∂x)^2
	temp = pout.dvy.z + pout.dvz.y;
	SijSij_bytwo += temp*temp;		// 2*SijSij += (∂vy/∂z + ∂vz/∂y)^2
	// Strain rate
	const float S = sqrtf(SijSij_bytwo);
	// production of turbulent kinetic energy (TKE)
	const float Pturb = fmin(pdata.turbVisc*SijSij_bytwo, 0.3f*pdata.keps_k*S);
	//const float Pturb = fmin(0.3f, 0.09f*pdata.keps_k/pdata.keps_e*S)*pdata.keps_k*S;

	// Variation terms for Dk/Dt and De/Dt for the partially implicit time integration in euler
	const float dkdt = Pturb + pout.diff_term_k;
	const float dedt = pdata.keps_e*1.44f*Pturb/fmax(pdata.keps_k,1e-6f) + pout.diff_term_e;

	params.keps_dkde[pdata.index].x = dkdt;
	params.keps_dkde[pdata.index].y = dedt;
	params.keps_dkde[pdata.index].z = pout.ce2yap;

	return d_visccoeff*pdata.vel.w;
}


/// A functor that clamps gamma and divides force by it,
/// but only for SA_BOUNDARY
template<BoundaryType>
struct gamma_fixup
{
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, OP &pout)
	{ /* do nothing */ }
};

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ void
gamma_fixup<SA_BOUNDARY>::with(FP const& params, P const& pdata, OP &pout)
{
	// check whether we are close to a wall
	if(pout.minlRas < 0.5f && !VERTEX(pdata.info)){
		// linear smoothing between eps/2 and eps
		const float sx = fmax(pout.minlRas*4.0f - 1.0f,0.0f);
		// smootherstep function
		const float smooth = (6.0f*sx*sx*sx*sx*sx-15.0f*sx*sx*sx*sx+10.0f*sx*sx*sx);
		// interpolated value of gamma
		const float intGam = pout.gamavg > 1e-5f ? pout.gamavg/pout.alpha : pout.gGam.w;
		pout.gGam.w = smooth*pout.gGam.w + (1.0f-smooth)*intGam;
	}
	// clipping gamma
	pout.gGam.w = fmin(fmax(pout.gGam.w, params.epsilon),1.0f);
	pout.force /= pout.gGam.w;
	// make sure that the velocity of vertices is orthogonal to its normal vector for keps
	if (VERTEX(pdata.info)){
		const float tmp = pout.force.w;
		pout.force -= dot3(pout.force, pout.gGam)*pout.gGam/sqlength3(pout.gGam);
		pout.force.w = tmp;
	}
}

/// A functor that writes out gamma,
/// but only for SA_BOUNDARY
template<BoundaryType>
struct write_gamma
{
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, OP const& pout) { /* do nothing */ }
};

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ void
write_gamma<SA_BOUNDARY>::with(FP const& params, P const& pdata, OP const& pout)
{ params.newGGam[pdata.index] = pout.gGam; }

/// A functor that writes out the mean vel,
/// but only for XSPH
template<bool>
struct write_xsph
{
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, OP const& pout)
	{ /* do nothing */ }
};

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ void
write_xsph<true>::with(FP const& params, P const& pdata, OP const& pout)
{ params.xsph[pdata.index] = make_float4(2.0f*pout.mean_vel, 0.0f); }

/// A functor that writes out turbvisc
/// but only for KEPSVISC
template<ViscosityType>
struct write_turbvisc
{
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, OP const& pout)
	{ /* do nothing */ }
};

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ void
write_turbvisc<KEPSVISC>::with(FP const& params, P const& pdata, OP const& pout)
{ params.turbvisc[pdata.index] = pdata.turbVisc; }


/// A functor that writes out forces
/// (no templatization, not needed)
struct write_forces
{
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, OP const& pout)
	{
		params.forces[pdata.index] = pout.force;
		params.contupd[pdata.index] = pout.contupd;
	}
};

/*
 * Global variables
 */

/// Some forces kernel specializations have global variables which are not individual particle data
/// and are therefore collected here

struct dyndt_shared_data
{
	float sm_max[BLOCK_SIZE_FORCES];
};

struct dyndt_keps_shared_data
{
	float sm_max_nut[BLOCK_SIZE_FORCES];
};

template<bool dyndt, ViscosityType visctype>
struct forces_shared_data // by default, depend on nothing
{
	// init shared data
	__device__ __forceinline__ void init() { /* do nothing */ }

	// store shared data
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__ void
	store(FP const& params, P const& pdata, OP const& pout)
	{ /* do nothing */ }

	// reduce shared data
	template<typename FP>
	__device__ __forceinline__ void reduce(FP const& params)
	{ /* do nothing */ }
};

template<ViscosityType visctype>
struct forces_shared_data<true, visctype> :
	dyndt_shared_data,
	COND_STRUCT(visctype == KEPSVISC, dyndt_keps_shared_data)
{
	// init shared data
	__device__ __forceinline__ void init()
	{ this->sm_max[threadIdx.x] = 0; }

	// auxiliary: store common dyndt shared data
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__ void
	store_sm_max(FP const& params, P const& pdata, OP const& pout)
	{
		this->sm_max[threadIdx.x] = max(length(as_float3(pout.force)), pdata.sspeed*pdata.sspeed/params.slength);
	}

	// auxiliary: reduce common dyndt shared data
	template<typename FP>
	__device__ __forceinline__ void reduce_sm_max(FP const& params)
	{ dtadaptBlockReduce(this->sm_max, params.cfl, params.cflOffset); }

	// store shared data
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__ void
	store(FP const& params, P const& pdata, OP const& pout)
	{ store_sm_max(params, pdata, pout); }

	// reduce shared data
	template<typename FP>
	__device__ __forceinline__ void reduce(FP const& params)
	{ reduce_sm_max(params); }
};

template<>
__device__ __forceinline__ void
forces_shared_data<true, KEPSVISC>::init()
{
	this->sm_max[threadIdx.x] = 0;
	this->sm_max_nut[threadIdx.x] = 0;
}

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ void
forces_shared_data<true, KEPSVISC>::store(FP const& params, P const& pdata, OP const& pout)
{
	store_sm_max(params, pdata, pout);
	this->sm_max_nut[threadIdx.x] = pdata.turbVisc;
}

template<>
template<typename FP>
__device__ __forceinline__ void
forces_shared_data<true, KEPSVISC>::reduce(FP const& params)
{
	reduce_sm_max(params);
	dtadaptBlockReduce(this->sm_max_nut, params.cfltvisc, params.cflOffset);
}


/************************************************************************************************************/
/*		   Kernels for computing forces with the different options											*/
/************************************************************************************************************/
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	BoundaryType boundarytype,
	ViscosityType visctype,
	bool dyndt,
	bool usexsph,
	bool usedem>
__global__ void
forcesDevice(
	forces_params<kerneltype, boundarytype, visctype, dyndt, usexsph> params)
{
	// Global particle index
	const uint index = INTMUL(blockIdx.x,blockDim.x) + threadIdx.x + params.fromParticle;

	__shared__ forces_shared_data<dyndt, visctype> shared;
	shared.init();

	// the body of this kernel easily gets a lot of indentation. to prevent that,
	// we wrap the main part into a do { } while(0); so that rather than
	// if (c1) { if (c2) { if (c3) { stuff } } } we can do
	// if (!c1) break; if (!c2) break ; if (!c3) break; stuff
	// to do stuff only if c1, c2, c3 are satisfied.
	// This makes the code more readable and collects common data retrieval operations
	// into one place.
	// (The alternative would have been a label before the reduction and a
	// bunch of goto label, but that would skip across initializations, which is an error.
	// and some people still don't like gotos, so this is actually a better alternative).
#pragma unroll
	do {
		if (index >= params.toParticle) break;

		// particle info struct, always stored in a texture
		const particleinfo info = tex1Dfetch(infoTex, index);

		// Determine if the current particle must act based on the particle type.
		// The particles for which forces are computed are:
		// * fluid particles
		// * object particles
		// * vertex particles (for SA_BOUNDARY)

		bool computes_stuff = FLUID(info) || OBJECT(info);
		if (boundarytype == SA_BOUNDARY)
			computes_stuff = computes_stuff || VERTEX(info);

		// nothing to do if the particle doesn't need to compute forces
		if (!computes_stuff)
			break;

		// cell-local position of the particle, stored in texture
		// or global memory depending on architecture
		#if( __COMPUTE__ >= 20)
		const float4 pos = params.posArray[index];
		#else
		const float4 pos = tex1Dfetch(posTex, index);
		#endif

		// nothing to do if the particle is inactive
		if (INACTIVE(pos))
			break;

		// load rest of particle data
		forces_particle_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph> const
			pdata(index, pos, info, params);

		// prepare particle output variables
		forces_particle_output<boundarytype, visctype, usexsph> pout;

		/* And finally the neib list transversal support */

		// persistent variables across getNeibData calls
		char neib_cellnum = 0;
		uint neib_cell_base_index = 0;
		float3 pos_corr;

		// under some conditions, some particles might want to skip the
		// neighbor list traversal. This is checked by the check() function of
		// the skip_neiblist struct. Any action that needs to be done then is
		// done by the prepare() function in the same struct.
		// Setting the neib list iterator counter i to d_neiblist_end to
		// actually skip the neib list traversal is done in here rather than
		// in the prepare() function.

		skip_neiblist<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph> skip;
		idx_t i = 0;

		if (skip.check(pdata)) {
			skip.prepare(pdata, pout);
			i = d_neiblist_end; // skip neighbors loop
		}

		// loop over all neighbors
		for (; i < d_neiblist_end; i += d_neiblist_stride) {
			neibdata neib_data = params.neibsList[i + index];

			if (neib_data == 0xffff) break;

			const uint neib_index = getNeibIndex(pdata.pos, pos_corr, params.cellStart,
				neib_data, pdata.gridPos, neib_cellnum, neib_cell_base_index);

			// Compute relative position vector and distance
			// Now relPos is a float4 and neib mass is stored in relPos.w
			#if( __COMPUTE__ >= 20)
			const float4 relPos = pos_corr - params.posArray[neib_index];
			#else
			const float4 relPos = pos_corr - tex1Dfetch(posTex, neib_index);
			#endif

			// skip inactive particles
			if (INACTIVE(relPos))
				continue;

			const float r = length3(relPos);

			const particleinfo neib_info = tex1Dfetch(infoTex, neib_index);

			// we now check if the current particle interacts with the neighbor.
			// We recycle the computes_stuff as boolean
			computes_stuff = (r < params.influenceradius);

			// Objects only interact with fluid particles, since object-object
			// and object-boundary forces are computed with ODE
			if (OBJECT(info))
				computes_stuff = computes_stuff && (FLUID(neib_info) && !OBJECT(neib_info));

			// with SA_BOUNDARY, fluid and vertex particles interact with any
			// BOUNDARY particles in the neiblist, regardless of distance
			// TODO FIXME they should interact with BOUNDARY particles such
			// that the current particle influence radius intersects the
			// boundary element
			if (boundarytype == SA_BOUNDARY && (FLUID(info) || VERTEX(info)))
				computes_stuff = computes_stuff || BOUNDARY(neib_info);

			// bail out if we do not interact with this neighbor
			if (!computes_stuff)
				continue;

			// load rest of neib data
			forces_neib_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph> const
				ndata(pdata, params, neib_index, neib_info, relPos, r);

			/* Contributions from this neighbor */
			forces_neib_output<boundarytype> nout;

			/* Now compute the interactions based on pdata.info and ndata.info */

			// Compute gamma_as and |grad gamma_as| and add it to the respective values
			// of the focal particle
			compute_gamma<boundarytype>::with<kerneltype>(params, pdata, ndata, pout, nout);

			if (FLUID(pdata.info)) {

				if (FLUID(ndata.info) || (boundarytype == SA_BOUNDARY && (BOUNDARY(ndata.info) || VERTEX(ndata.info)) ) ) {

					// computes d\rho/dt, including ferrari correction
					compute_density_derivative<boundarytype>::with<sph_formulation>(params, pdata, ndata, pout, nout);
					pout.force.w += nout.DrDt;
					pout.contupd.x += nout.contDiff;
					pout.contupd.y += nout.DgamDt;

					// compute pressure part of acceleration
					compute_pressure_contrib<boundarytype>::with<sph_formulation>(params, pdata, ndata, pout, nout);

					// compute viscous forces
					compute_viscous_contrib<boundarytype>::with<visctype>(params, pdata, ndata, pout, nout);

					// compute diffusion terms for k-epsilon and the strain rate tensor
					compute_keps_term<boundarytype, visctype>::with(params, pdata, ndata, pout, nout);

					// Compute mean velocity for the use in the XSPH variant. Contribution added in euler.
					compute_mean_vel<usexsph>::with<kerneltype>(params, pdata, ndata, pout, nout);

				} else {
					compute_repulsive_force<boundarytype>::with(params, pdata, ndata, pout, nout);
				}

			}
			else if (boundarytype == SA_BOUNDARY && visctype == KEPSVISC && VERTEX(info)) {
				// For vertex particles: Compute viscous force as Dv/Dt = div(\nu grad(v)), only in KEPS these are actually used
				compute_viscous_contrib<boundarytype>::with<visctype>(params, pdata, ndata, pout, nout);
			}
			else if (OBJECT(info)) {
				compute_repulsive_force<boundarytype>::with(params, pdata, ndata, pout, nout);
				// TODO FIXME (Alexis): why are we multiplying with the mass here? This seems dimensionally incorrect
				nout.DvDt *= ndata.relPos.w;
			}

			// sum all contributions from the neighbours in the force array
			as_float3(pout.force) += nout.DvDt;

		} // end of loop over neighbors

		// External forces etc
		if (FLUID(info)) {

			// For SA_BOUNDARY: divides forces by gamma; else: does nothing
			gamma_fixup<boundarytype>::with(params, pdata, pout);

			// post-processing for viscous terms, returns viscous coefficient
			// to be used with planes/DEM
			// for KEPS: finalizes computation of strain rate & computes de/dt and dk/dt
			const float dynvisc = viscous_fixup<visctype>::with(params, pdata, pout);

			// Adding gravity
			as_float3(pout.force) += d_gravity;

			// TODO: check for time step limitation in case of geometrical boundaries (DEM or planes)
			// for viscous fluids
			float geom_coeff = 0.0f;

			const float3 globalpos = d_worldOrigin + as_float3(pdata.pos) + pdata.gridPos*d_cellSize + 0.5f*d_cellSize;

			// Adding repulsive force computed from DEM
			if (usedem) {
				switch (boundarytype) {
					case LJ_BOUNDARY:
						geom_coeff = DemLJForce(demTex, globalpos,
								pdata.pos.w, as_float3(pdata.vel), dynvisc, pout.force);
						break;
					default:
						break;
				}
			}

			// Adding repulsive force computed from geometric boundaries
			if (d_numplanes) {
				geom_coeff = max(geom_coeff,
					GeometryForce(globalpos,
							pdata.pos.w, as_float3(pdata.vel), dynvisc, pout.force));
			}

			shared.store(params, pdata, pout);
		}
		else if (VERTEX(info)) {
			// For SA_BOUNDARY: divides forces by gamma; else: does nothing
			gamma_fixup<boundarytype>::with(params, pdata, pout);
		}

		// Writing out the results
		if (OBJECT(info)) {
			params.rbforces[pdata.rbindex] = pout.force;
			params.rbtorques[pdata.rbindex] = make_float4(
				cross(d_worldOrigin + as_float3(pdata.pos) + pdata.gridPos*d_cellSize + 0.5f*d_cellSize
								- d_rbcg[object(info)], as_float3(pout.force)));
		} else {
			write_forces::with(params, pdata, pout);
			write_gamma<boundarytype>::with(params, pdata, pout);
		}

		if (FLUID(info)) {
			write_xsph<usexsph>::with(params, pdata, pout);
			write_turbvisc<visctype>::with(params, pdata, pout);
		}

	} while (0);

	shared.reduce(params);
}
/************************************************************************************************************/

#endif

/* vi:set ft=cuda: */
