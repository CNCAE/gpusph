/*  Copyright 2011-2013 Alexis Herault, Giuseppe Bilotta, Robert A. Dalrymple, Eugenio Rustico, Ciro Del Negro

    Istituto Nazionale di Geofisica e Vulcanologia
        Sezione di Catania, Catania, Italy

    Università di Catania, Catania, Italy

    Johns Hopkins University, Baltimore, MD

    This file is part of GPUSPH.

    GPUSPH is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    GPUSPH is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with GPUSPH.  If not, see <http://www.gnu.org/licenses/>.
*/

/* Auxiliary data types and device functions used in forces kernel.
   These must only be defined once, so fence them.
 */

#ifndef _FORCES_KERNEL_AUX
#define _FORCES_KERNEL_AUX

/// Precompute pressure contribution to the momemntum equation.
/// Two versions are available, one in the KEPS viscosity case,
/// and a generic one

// Generic:
template<SPHFormulation sph_formulation>
__device__ __forceinline__
float
precalc_pressure(const float rho, particleinfo const& info);

/* when using SPH formulation 1, the precomputed pressure contribution
   for the current particle is p/rho^2 */
template<>
__device__ __forceinline__
float
precalc_pressure<SPH_F1>(const float rho, particleinfo const& info)
{
	return P(rho, PART_FLUID_NUM(info))/(rho*rho);
}

/* when using SPH formulation 2, the precomputed pressure contribution
   for the current particle is just p */
template<>
__device__ __forceinline__
float
precalc_pressure<SPH_F2>(const float rho, particleinfo const& info)
{
	return P(rho, PART_FLUID_NUM(info));
}

// With KEPS visc
template<SPHFormulation sph_formulation>
__device__ __forceinline__
float
precalc_pressure(const float rho, particleinfo const& info, const float keps_k)
{
	// in case of k-e model we use p~ = p + 2/3*rho*k
	// TODO FIXME so far this has only been done for SPH_F1,
	// check if this is also valid for SPH_F2
	return precalc_pressure<sph_formulation>(rho, info) + 2*keps_k/rho/3;
}

/* Compute the square of the at-rest speed of sound */
__device__ __forceinline__
float
get_sqC0(particleinfo const& info)
{
	float c0 = d_sscoeff[PART_FLUID_NUM(info)];
	return c0*c0;
}


/*
 * Particle data
 */

// The amount and type of particle data retrieved for the current particle
// being processed and for the neighbor particle depend on a variety of factors,
// including SPH formulation, boundary type, viscosity etc, but also the
// particle type (fluid, object, boundary, vertex). We use a conditional struct
// assembly mechanism similar to the one seen in src/forces_params.h

// TODO FIXME for the time being, include everything unconditionally
#define _UNCONDITIONALLY_INCLUDE_ALL_STRUCTS 1
#if _UNCONDITIONALLY_INCLUDE_ALL_STRUCTS
#undef COND_STRUCT
#define COND_STRUCT(some_cond, some_struct) some_struct
#endif

// data used for all particles
struct common_particle_data
{
	const	particleinfo	info;
	const	float4	pos;
	const	int3	gridPos;

	__device__ __forceinline__
	common_particle_data(const uint index, float4 const& _pos, particleinfo const& _info, hashKey const* hash) :
		info(_info),
		pos(_pos),
		gridPos(calcGridPosFromParticleHash(hash[index]))
	{}
};

// data used only for objects
struct rb_particle_data
{
	const	uint	rbindex;

	__device__ __forceinline__
	rb_particle_data(particleinfo const& info) : rbindex(id(info) + d_rbstartindex[object(info)])
	{}
};

// velocity. used for:
// * fluid particles
// * vertex particles if KEPSVISC
struct vel_particle_data
{
	const	float4	vel;

	__device__ __forceinline__
	vel_particle_data(const uint index) : vel(tex1Dfetch(velTex, index))
	{}
};

// speed of sound
// used only for dyndt, ARTVISC or SA_BOUNDARY
struct sspeed_particle_data
{
	const	float	sspeed;

	__device__ __forceinline__
	sspeed_particle_data(const float rho, particleinfo const& info) :
		sspeed(soundSpeed(rho, PART_FLUID_NUM(info)))
	{}
};

// data used for SA_BOUNDARY
struct sa_boundary_particle_data
{
	// square of at-rest sound speed. Would need modifications for multifluid
	// This is used by fluid particles only
	// TODO this should be computed once on the host and loaded into constant memory
	const	float	sqC0;

	// does this particle want to (re)compute gamma? see logic below
	// this is used by vertex particles only
			bool	computeGamma;

	// oldGGam would hold the previous value of gamma (in .w) and its gradient (in .xyz).
	// When we want to (re)compute gamma, the old gradient is only used for the
	// computation of solid angles for gamma, for which we actually need the
	// opposite, normalized vector. In this case, when loading oldGGam we
	// therefore proceed to the normalization and sign-change of the gradient
	// part, preserving .w
	const	float4	oldGGam;

	// For fluid particles, we always want to recompute gamma, while for vertex
	// particles we only want to recompute if we have moving boundaries or if
	// gamma itself has not been computed before, where ‘computed before’ is
	// assessed by checking if its value is less than the given epsilon

	// fluid init
	__device__ __forceinline__
	sa_boundary_particle_data(const uint index, particleinfo const& info,
		const float epsilon, const bool movingBoundaries) :
		sqC0(get_sqC0(info)),
		computeGamma(FLUID(info) || (VERTEX(info) && movingBoundaries)),
		// the actual oldGGam loading: this will also set computeGamma true if
		// it was false but .w was < epsilon
		oldGGam(fetchNormalizedOldGamma(index, epsilon, computeGamma))
		// now oldGGam holds the old value of gamma if computeGamma == false,
		// and the renormalized gradient in .xyz if computeGamma == true
	{}
};

// SPSVISC particle data
struct sps_particle_data
{
	const	symtensor3	tau;

	__device__ __forceinline__
	sps_particle_data(const uint index) : tau(fetchTau(index))
	{}
};

// KEPSVISC particle data
struct keps_particle_data
{
	const	float	keps_k;
	const	float	keps_e;
	const	float	turbVisc;

	__device__ __forceinline__
	keps_particle_data(const uint index, particleinfo const& info) :
		keps_k(tex1Dfetch(keps_kTex, index)),
		keps_e( tex1Dfetch(keps_eTex, index)),
		turbVisc(FLUID(info) ? 0.09f*keps_k*keps_k/keps_e : 0)
	{}
};

// Precomputed pressure contribution
// Automatic initialization of this beast is a bit messy because
// (1) we want it to be const
// (2) the initialization depends on SPH formulation and viscosity type
// (3) with KEPSVISC it needs one additional parameter
// (4) the value passed to the additional parameter only exists in the KEPSVISC case
// so the caller must be able to feed the last parameter correctly if it exsists,
// but not even try to provide it otherwise.
// The solution is to make this a templatized structure based on
// SPH formulation, plus the typename of an additional parameter, which
// will be the structure containing keps_k in the case of KEPSVISC.
// Suggestions for a better solution are welcome
template<SPHFormulation sph_formulation, typename T>
struct p_precalc_particle_data
{
	const	float	p_precalc;

	// default initializer, extra param is ignored
	__device__ __forceinline__
	p_precalc_particle_data(const float rho, particleinfo const& info, T const&) :
		p_precalc(precalc_pressure<sph_formulation>(rho, info))
	{}
};

// specialize the initializer
template<SPHFormulation sph_formulation>
struct p_precalc_particle_data<sph_formulation, keps_particle_data>
{
	const	float	p_precalc;

	__device__ __forceinline__
	p_precalc_particle_data(const float rho, particleinfo const& info, keps_particle_data const& ke) :
		p_precalc(precalc_pressure<sph_formulation>(rho, info, ke.keps_k))
	{}
};

// KEPSVISC precalc data, used only for fluid particles
// again, turbVisc should only be actually accessed by the caller if we are with KEPSVISC,
// so we assume the caller passes us a full keps_particle_data structure
// (which they will only do in the KEPSVISC case)
struct keps_precalc_particle_data
{
	const	float	dkdt_precalc;
	const	float	dedt_precalc;

	__device__ __forceinline__
	keps_precalc_particle_data(const float rho, keps_particle_data const& ke) :
		dkdt_precalc(rho*(d_visccoeff + ke.turbVisc)),
		dedt_precalc(rho*(d_visccoeff + ke.turbVisc/1.3f))
	{}
};

// And now we assemble them. Not all particle types require all particle data,
// but for the time being we don't optimize this far and just limit ourselves
// to conditional inclusions based on kernel specialization only, not particle tye

template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	BoundaryType boundarytype,
	ViscosityType visctype,
	bool dyndt, bool usexsph>
struct forces_particle_data :
	// included unconditionally for all particles:
	common_particle_data,
	// the next is only needed for PT_OBJECT, which in fact need no other data
	rb_particle_data,
	// vel included unconditionally for all particles, even though
	// PT_VERTEX only use them for KEPSVISC, and
	// PT_OBJECT don't use them
	vel_particle_data,
	// SA_BOUNDARY data (always needed by PT_VERTEX, since they only obviously
	// appear with SA_BOUNDARY)
	COND_STRUCT(boundarytype == SA_BOUNDARY,
		sa_boundary_particle_data),
	// KEPSVISC data, needed by both PT_FLUID and PT_VERTEX
	COND_STRUCT(visctype == KEPSVISC,
		keps_particle_data),
	// everything else is just for PT_FLUID
	COND_STRUCT(visctype == SPSVISC,
		sps_particle_data),
	COND_STRUCT(dyndt || (visctype == ARTVISC) || (boundarytype == SA_BOUNDARY),
		sspeed_particle_data),
	// to see why this is so messy, see definition of p_precalc_particle_data
	p_precalc_particle_data<sph_formulation,
		COND_STRUCT(visctype == KEPSVISC, keps_particle_data)>,
	COND_STRUCT(visctype == KEPSVISC,
		keps_precalc_particle_data)
{
	ParticleType	ptype;

	// determine specialization automatically based on info and params
	__device__ __forceinline__
	forces_particle_data(const uint _index, float4 const& _pos, particleinfo const& _info,
		forces_params<kerneltype, boundarytype, visctype, dyndt, usexsph> const& params) :
		common_particle_data(_index, _pos, _info, params.particleHash),
		rb_particle_data(_info),
		vel_particle_data(_index),
		COND_STRUCT(boundarytype == SA_BOUNDARY,
			sa_boundary_particle_data)(_index, _info, params.epsilon, params.movingBoundaries),
		COND_STRUCT(visctype == KEPSVISC,
			keps_particle_data)(_index, _info),
		COND_STRUCT(visctype == SPSVISC,
			sps_particle_data)(_index),
		COND_STRUCT(dyndt || (visctype == ARTVISC) || (boundarytype == SA_BOUNDARY),
			sspeed_particle_data)(vel.w, _info),
		p_precalc_particle_data<sph_formulation,
			COND_STRUCT(visctype == KEPSVISC, keps_particle_data)>(vel.w, _info, *this),
		COND_STRUCT(visctype == KEPSVISC, keps_precalc_particle_data)(vel.w, *this),
		ptype(static_cast<ParticleType>PART_TYPE(_info))
	{}
};

/// Similarly for the output variables

// common
struct common_particle_output
{
	float4	force;

	__device__ __forceinline__
	common_particle_output() : force(make_float4(0.0f))
	{}
};

// SA_BOUNDARY
struct sa_boundary_particle_output
{
	float4	gGam;

	__device__ __forceinline__
	sa_boundary_particle_output() : gGam(make_float4(0, 0, 0, 1))
	{}
};

// KEPSVISC
struct keps_particle_output
{
	float3	dvx;
	float3	dvy;
	float3	dvz;

	float	diff_term_k;
	float	diff_term_e;

	__device__ __forceinline__
	keps_particle_output()
	{
		dvx = dvy = dvz = make_float3(0.0f);
		diff_term_k = diff_term_e = 0;
	}
};

// XSPH
struct xsph_particle_output
{
	float3	mean_vel;

	__device__ __forceinline__
	xsph_particle_output() : mean_vel(make_float3(0.0f))
	{}
};

template<BoundaryType boundarytype,
	ViscosityType visctype,
	bool usexsph>
struct forces_particle_output :
	common_particle_output,
	COND_STRUCT(boundarytype == SA_BOUNDARY, sa_boundary_particle_output),
	COND_STRUCT(visctype == KEPSVISC, keps_particle_output),
	COND_STRUCT(usexsph, xsph_particle_output)
{
	__device__ __forceinline__
	forces_particle_output() :
		common_particle_output(),
		COND_STRUCT(boundarytype == SA_BOUNDARY, sa_boundary_particle_output)(),
		COND_STRUCT(visctype == KEPSVISC, keps_particle_output)(),
		COND_STRUCT(usexsph, xsph_particle_output)()
	{}
};

/*
 * Neib data
 */

// Just like for particle data, we collect neib data into appropriate structures

// data used fo all neibs
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	BoundaryType boundarytype,
	ViscosityType visctype,
	bool dyndt, bool usexsph>
struct common_neib_data
{
	// we will get as arguments also the current particle data and forces_kernel params.
	// Define shorthands for their data type
	typedef forces_particle_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph> pdata_t;
	typedef forces_params<kerneltype, boundarytype, visctype, dyndt, usexsph> params_t;

	const	particleinfo	info;
	// relPos holds the distance vector in .xyz and the neib mass in .w
	const	float4	relPos;
	const	float	r;

	// relVel holds the relative velocity in .xyz and the neib density in .w
	const	float4	relVel;
	const	float	vel_dot_pos;
	const	float	f;

	__device__ __forceinline__
	common_neib_data(pdata_t const& pdata, params_t const& params,
		const uint _index, particleinfo const& _info,
		float4 const& _relPos, const float _r) :
		info(_info), relPos(_relPos), r(_r),
		relVel(as_float3(pdata.vel) - tex1Dfetch(velTex, _index)),
		vel_dot_pos(dot3(relVel, relPos)),
		f(F<kerneltype>(r, params.slength))
	{}
};

template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	BoundaryType boundarytype,
	ViscosityType visctype,
	bool dyndt, bool usexsph>
struct sa_boundary_neib_data
{
	// we will get as arguments also the current particle data and forces_kernel params.
	// Define shorthands for their data type
	typedef forces_particle_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph> pdata_t;
	typedef forces_params<kerneltype, boundarytype, visctype, dyndt, usexsph> params_t;

	const	float4	belem;
	const	float3&	normal_s;
	const	float2	gamAS; // gamAS as used by ptype == PT_FLUID, gamES as used by ptype == PT_VERTEX

	__device__ __forceinline__
	sa_boundary_neib_data(pdata_t const& pdata,  params_t const& params,
		const uint index, float4 const& _relPos) :
		belem(tex1Dfetch(boundTex, index)),
		normal_s(as_float3(belem)),
#if _UNCONDITIONALLY_INCLUDE_ALL_STRUCTS
		gamAS(boundarytype == SA_BOUNDARY ?
			Gamma<kerneltype>(params.slength, _relPos,
				params.vertPos0[index], params.vertPos1[index], params.vertPos2[index],
				belem, pdata.oldGGam, params.epsilon, pdata.computeGamma) :
			make_float2(NAN))
#else
		gamAS(Gamma<kerneltype>(params.slength, _relPos,
				params.vertPos0[index], params.vertPos1[index], params.vertPos2[index],
				belem, pdata.oldGGam, params.epsilon, pdata.computeGamma))
#endif
	{}
};

template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	BoundaryType boundarytype,
	ViscosityType visctype,
	bool dyndt, bool usexsph>
struct forces_neib_data :
	common_neib_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph>,
// TODO FIXME for the time being, include everything unconditionally
// can't use COND_STRUCT here because of the commas in the sa_boundary_neib_data template def
#if _UNCONDITIONALLY_INCLUDE_ALL_STRUCTS
	sa_boundary_neib_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph>,
#else
	conditional<boundarytype == SA_BOUNDARY,
		sa_boundary_neib_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph>,
		empty< sa_boundary_neib_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph> >::type,
#endif
	// these are the same as the particle data
	COND_STRUCT(visctype == KEPSVISC, keps_particle_data),
	COND_STRUCT(visctype == SPSVISC, sps_particle_data),
	COND_STRUCT(boundarytype == SA_BOUNDARY, sspeed_particle_data)
{
	// shortcut typedefs
	typedef common_neib_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph> _common_neib_data;
	typedef
#if _UNCONDITIONALLY_INCLUDE_ALL_STRUCTS
		sa_boundary_neib_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph>
#else
		typename conditional<boundarytype == SA_BOUNDARY,
			sa_boundary_neib_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph>,
			empty< sa_boundary_neib_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph> >::type
#endif
		_sa_boundary_neib_data;
	typedef typename _common_neib_data::pdata_t pdata_t;
	typedef typename _common_neib_data::params_t params_t;

	ParticleType	ntype;

	__device__ __forceinline__
	forces_neib_data(pdata_t const& pdata, params_t const& params,
		const uint _index, particleinfo const& _info,
		float4 const& _relPos, const float _r) :
		_common_neib_data(pdata, params, _index, _info, _relPos, _r),
		_sa_boundary_neib_data(pdata, params, _index, _relPos),
		COND_STRUCT(visctype == KEPSVISC, keps_particle_data)(_index, _info),
		COND_STRUCT(visctype == SPSVISC, sps_particle_data)(_index),
		COND_STRUCT(boundarytype == SA_BOUNDARY || visctype == ARTVISC, sspeed_particle_data)(this->relVel.w, _info),
		ntype(static_cast<ParticleType>PART_TYPE(_info))
	{}
};

/// And finally the neib contribution to the current particle forces
struct common_neib_output
{
	// acceleration
	float	DvDt;
	// density derivative
	float	DrDt;

	__device__ __forceinline__
	common_neib_output() : DvDt(0), DrDt(0)
	{}
};

struct sa_boundary_neib_output
{
	float3	bound_term_pres;
	float3	bound_term_visc;

	__device__ __forceinline__
	sa_boundary_neib_output() {
		bound_term_pres = make_float3(0.0f);
		bound_term_visc = make_float3(0.0f);
	}
};

template<BoundaryType boundarytype>
struct forces_neib_output :
	common_neib_output,
	COND_STRUCT(boundarytype == SA_BOUNDARY, sa_boundary_neib_output)
{
	__device__ __forceinline__
	forces_neib_output() :
		common_neib_output(),
		COND_STRUCT(boundarytype == SA_BOUNDARY, sa_boundary_neib_output)()
	{}
};


/*
 * A lot of parts of the forces kernel behave very differently based on some template parameters.
 * We isolate this behavior in template functions defined (and specialized) here.
 * TODO FIXME the syntax of these functors could be OH SO MUCH CLEANER if we could use C++11 ...
 */

/// The next set of functions check  if the given particle (pdata) should skip
/// traversing the neib list, and define the actions to be taken when skipping.
/// Since we need partial specialization, they cannot be actual functions.
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	BoundaryType boundarytype,
	ViscosityType visctype,
	bool dyndt, bool usexsph>
struct skip_neiblist
{
	// typedefs to shorten argument types
	typedef forces_particle_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph> pdata_t;
	typedef forces_particle_output<boundarytype, visctype, usexsph> pout_t;

	/// check if the given particle must skip the neiblist traversal
	__device__ __forceinline__
	bool check(pdata_t const& pdata)
	{
		return false; // default, don't skip
	}

	/// do anything that is needed to actually skip the neiblist traversal
	__device__ __forceinline__
	void prepare(pdata_t const& pdata, pout_t &pout)
	{ /* do nothing by default */ }

};

template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	ViscosityType visctype,
	bool dyndt, bool usexsph>
struct skip_neiblist<kerneltype, sph_formulation, SA_BOUNDARY, visctype, dyndt, usexsph>
{
	// typedefs to shorten argument types
	typedef forces_particle_data<kerneltype, sph_formulation, SA_BOUNDARY, visctype, dyndt, usexsph> pdata_t;
	typedef forces_particle_output<SA_BOUNDARY, visctype, usexsph> pout_t;

	__device__ __forceinline__
	bool check(pdata_t const& pdata)
	{
		// vertex particles will skip neighbors unless they need to compute gamma,
		// or when using KEPSVISC
		return visctype != KEPSVISC && (pdata.ptype == PT_VERTEX) && !pdata.computeGamma;
	}

	__device__ __forceinline__
	void prepare(pdata_t const& pdata, pout_t &pout)
	{
		// FIXME currently we can expect it to be a vertex particle, and this is what
		// we need to do, but in the future there might be other cases too
		pout.gGam = pdata.oldGGam;
	}
};

/*
 * Computing neighbor contributions
 */

/// A functor that computes the scalar viscous coefficient (plus additional optional contributions
/// directly to pout and/or nout.
/// Beware that specializations on the ViscosityType will require two template<> specifications:
/// the first to absorb the visctype, and the other to indicate P, N, OP and ON
template<ViscosityType visctype>
struct compute_visc {
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__ float
	operator()(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout);
};

template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ float
compute_visc<DYNAMICVISC>::operator()(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	return laminarvisc_dynamic(pdata.vel.w, ndata.relVel.w, ndata.relPos.w, ndata.f,
		d_visccoeff*pdata.vel.w, d_visccoeff*ndata.relVel.w);
}

template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ float
compute_visc<KINEMATICVISC>::operator()(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	return laminarvisc_kinematic(pdata.vel.w, ndata.relVel.w, ndata.relPos.w, ndata.f);
}

// SPS viscosity is just kinematic + a direct contribution to the force
template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ float
compute_visc<SPSVISC>::operator()(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	pout.force.x += ndata.relPos.w*ndata.f*(
		(pdata.tau.xx + ndata.tau.xx)*ndata.relPos.x +
		(pdata.tau.xy + ndata.tau.xy)*ndata.relPos.y +
		(pdata.tau.xz + ndata.tau.xz)*ndata.relPos.z);
	pout.force.y += ndata.relPos.w*ndata.f*(
		(pdata.tau.xy + ndata.tau.xy)*ndata.relPos.x +
		(pdata.tau.yy + ndata.tau.yy)*ndata.relPos.y +
		(pdata.tau.yz + ndata.tau.yz)*ndata.relPos.z);
	pout.force.z += ndata.relPos.w*ndata.f*(
		(pdata.tau.xz + ndata.tau.xz)*ndata.relPos.x +
		(pdata.tau.yz + ndata.tau.yz)*ndata.relPos.y +
		(pdata.tau.zz + ndata.tau.zz)*ndata.relPos.z);
	return laminarvisc_kinematic(pdata.vel.w, ndata.relVel.w, ndata.relPos.w, ndata.f);
}

// k-e viscosity: dynamic + turbulent
template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ float
compute_visc<KEPSVISC>::operator()(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	return laminarvisc_dynamic(pdata.vel.w, ndata.relVel.w, ndata.relPos.w, ndata.f,
		(d_visccoeff+pdata.turbVisc)*pdata.vel.w, (d_visccoeff+ndata.turbVisc)*ndata.relVel.w);
}

// artificial viscosity contributes directly to DvDt, so it returns 0 as viscosity scalar value
template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ float
compute_visc<ARTVISC>::operator()(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	if (ndata.vel_dot_pos < 0.0f)
		nout.DvDt += artvisc(ndata.vel_dot_pos, pdata.vel.w, ndata.relVel.w,
			pdata.sspeed, ndata.sspeed, ndata.r, params.slength);
	return 0;
}


/*
 * Post-processing and saving
 */

/// The next of functors are called by the post_processor

/// A functor that clamps gamma and divides force by it,
/// but only for SA_BOUNDARY
template<BoundaryType>
struct _divideForceByGamma
{
	template<typename OUT, typename PAR>
	__device__ __forceinline__ void
	operator()(OUT &pout, PAR const& params)
	{ /* do nothing */ }
};

template<>
struct _divideForceByGamma<SA_BOUNDARY>
{
	template<typename OUT, typename PAR>
	__device__ __forceinline__ void
	operator()(OUT &pout, PAR const& params)
	{
		pout.gGam.w = fmin(fmax(pout.gGam.w, params.epsilon),1.0f);
		pout.force /= pout.gGam.w;
	}
};

/// A functor that writes out gamma,
/// but only for SA_BOUNDARY
template<BoundaryType>
struct _write_gamma
{
	template<typename OUT, typename PAR>
	__device__ __forceinline__ void
	operator()(OUT const& pout, PAR &params, const uint index)
	{ /* do nothing */ }
};

template<>
struct _write_gamma<SA_BOUNDARY>
{
	template<typename OUT, typename PAR>
	__device__ __forceinline__ void
	operator()(OUT const& pout, PAR &params, const uint index)
	{ params.newGGam[index] = pout.gGam; }
};

/// A functor that writes out the mean vel,
/// but only for XSPH
template<bool>
struct _write_xsph
{
	template<typename OUT, typename PAR>
	__device__ __forceinline__ void
	operator()(OUT const& pout, PAR &params, const uint index)
	{ /* do nothing */ }
};

template<>
struct _write_xsph<true>
{
	template<typename OUT, typename PAR>
	__device__ __forceinline__ void
	operator()(OUT const& pout, PAR &params, const uint index)
	{ params.xsph[index] = make_float4(2.0f*pout.mean_vel, 0.0f); }
};

/// A functor that writes out turbvisc
/// but only for KEPSVISC
template<ViscosityType>
struct _write_turbvisc
{
	template<typename OUT, typename PAR>
	__device__ __forceinline__ void
	operator()(OUT const& pdata, PAR &params, const uint index)
	{ /* do nothing */ }
};

template<>
struct _write_turbvisc<KEPSVISC>
{
	template<typename OUT, typename PAR>
	__device__ __forceinline__ void
	operator()(OUT const& pdata, PAR &params, const uint index)
	{ params.turbvisc[index] = pdata.turbVisc; }
};



/// Post-processing of forces and writing out the results
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	BoundaryType boundarytype,
	ViscosityType visctype,
	bool dyndt, bool usexsph>
struct post_processor_t
{
	typedef forces_params<kerneltype, boundarytype, visctype, dyndt, usexsph> params_t;
	typedef forces_particle_output<boundarytype, visctype, usexsph> pout_t;
	typedef forces_particle_data<kerneltype, sph_formulation, boundarytype, visctype, dyndt, usexsph> pdata_t;

	uint	const&	index;
	pdata_t	const&	pdata;
	pout_t		&pout;
	params_t	&params;

	__device__ __forceinline__
	post_processor_t(uint const& _index, pdata_t const& _pdata,
		pout_t &_pout, params_t &_params) :
		index(_index), pdata(_pdata), pout(_pout), params(_params)
	{};

	/// Dividing force by gamma. Only done with SA_BOUNDARY
	__device__ __forceinline__ void
	divideForceByGamma()
	{ _divideForceByGamma<boundarytype>()(pout, params); }

	// write forces to global memory
	__device__ __forceinline__ void
	write_forces() { params.forces[index] = pout.force; }

	// write gamma to global memory
	__device__ __forceinline__ void
	write_gamma()
	{ _write_gamma<boundarytype>()(pout, params, index); }

	// write xsph to global memory
	__device__ __forceinline__ void
	write_xsph()
	{ _write_xsph<usexsph>()(pout, params, index); }

	// write turbvisc to global memory
	__device__ __forceinline__ void
	write_turbvisc()
	{ _write_turbvisc<visctype>()(pdata, params, index); }
};





#endif

// the rest is included multiple times, so no fencing

#ifdef XSPH_KERNEL
#	ifdef DT_KERNEL
#		define FORCES_CUDA_KERNEL FORCES_KERNEL_NAME(VISC_TYPE, Xsph, Dt)
#	else
#		define FORCES_CUDA_KERNEL FORCES_KERNEL_NAME(VISC_TYPE, Xsph,)
#	endif
#else
#	ifdef DT_KERNEL
#		define FORCES_CUDA_KERNEL FORCES_KERNEL_NAME(VISC_TYPE,, Dt)
#	else
#		define FORCES_CUDA_KERNEL FORCES_KERNEL_NAME(VISC_TYPE,,)
#	endif
#endif

/************************************************************************************************************/
/*		   Kernels for computing forces with the different options											*/
/************************************************************************************************************/
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	BoundaryType boundarytype,
#if 0 // TODO FIXME not yet
	ViscosityType visctype,
	bool dyndt,
	bool usexsph,
#endif
	bool usedem>
__global__ void
FORCES_CUDA_KERNEL(
	forces_params<kerneltype, boundarytype, VISC_TYPE, DYNDT, USEXSPH> params)
{
	// Global particle index
	const uint index = INTMUL(blockIdx.x,blockDim.x) + threadIdx.x;
	# ifdef DT_KERNEL
	__shared__ float sm_max[BLOCK_SIZE_FORCES];
	sm_max[threadIdx.x] = 0.0f;
	# ifdef VISC_KEPS
	__shared__ float sm_max_nut[BLOCK_SIZE_FORCES];
	sm_max_nut[threadIdx.x] = 0.0f;
	# endif
	# endif

	// the body of this kernel easily gets a lot of indentation. to prevent that,
	// we wrap the main part into a do { } while(0); so that rather than
	// if (c1) { if (c2) { if (c3) { stuff } } } we can do
	// if (!c1) break; if (!c2) break ; if (!c3) break; stuff
	// to do stuff only if c1, c2, c3 are satisfied.
	// This makes the code more readable and collects common data retrieval operations
	// into one place.
	// (The alternative would have been a label before the reduction and a
	// bunch of goto label, but that would skip across initializations, which is an error.
	// and some people still don't like gotos, so this is actually a better alternative).
#pragma unroll
	do {
		if (index >= params.numParticles)
			break;

		// particle info struct, always stored in a texture
		const particleinfo info = tex1Dfetch(infoTex, index);

		// Determine if the current particle must act based on the particle type.
		// The particles for which forces are computed are:
		// * fluid particles
		// * object particles
		// * vertex particles (for SA_BOUNDARY)

		bool computes_stuff = FLUID(info) || OBJECT(info);
		if (boundarytype == SA_BOUNDARY)
			computes_stuff = computes_stuff || VERTEX(info);

		// nothing to do if the particle doesn't need to compute forces
		if (!computes_stuff)
			break;

		// cell-local position of the particle, stored in texture
		// or global memory depending on architecture
		#if( __COMPUTE__ >= 20)
		const float4 pos = params.posArray[index];
		#else
		const float4 pos = tex1Dfetch(posTex, index);
		#endif

		// nothing to do if the particle is inactive
		if (INACTIVE(pos))
			break;

		// load rest of particle data
		forces_particle_data<kerneltype, sph_formulation, boundarytype, VISC_TYPE, DYNDT, USEXSPH> const
			pdata(index, pos, info, params);

		// prepare particle output variables
		forces_particle_output<boundarytype, VISC_TYPE, USEXSPH> pout;

		/* And finally the neib list transversal support */

		// persistent variables across getNeibData calls
		char neib_cellnum = 0;
		uint neib_cell_base_index = 0;
		float3 pos_corr;

		// under some conditions, some particles might want to skip the
		// neighbor list traversal. This is checked by the check() function of
		// the skip_neiblist struct. Any action that needs to be done then is
		// done by the prepare() function in the same struct.
		// Setting the neib list iterator counter i to d_neiblist_end to
		// actually skip the neib list traversal is done in here rather than
		// in the prepare() function.

		skip_neiblist<kerneltype, sph_formulation, boundarytype, VISC_TYPE, DYNDT, USEXSPH> skip;
		idx_t i = 0;

		if (skip.check(pdata)) {
			skip.prepare(pdata, pout);
			i = d_neiblist_end; // skip neighbors loop
		}

		// loop over all neighbors
		for (; i < d_neiblist_end; i += d_neiblist_stride) {
			neibdata neib_data = params.neibsList[i + index];

			if (neib_data == 0xffff) break;

			const uint neib_index = getNeibIndex(pdata.pos, pos_corr, params.cellStart,
				neib_data, pdata.gridPos, neib_cellnum, neib_cell_base_index);

			// Compute relative position vector and distance
			// Now relPos is a float4 and neib mass is stored in relPos.w
			#if( __COMPUTE__ >= 20)
			const float4 relPos = pos_corr - params.posArray[neib_index];
			#else
			const float4 relPos = pos_corr - tex1Dfetch(posTex, neib_index);
			#endif

			// skip inactive particles
			if (INACTIVE(relPos))
				continue;

			const float r = length3(relPos);

			const particleinfo neib_info = tex1Dfetch(infoTex, neib_index);

			// we now check if the current particle interacts with the neighbor.
			// We recycle the computes_stuff as boolean
			computes_stuff = (r < params.influenceradius);

			// Objects only interact with fluid particles, since object-object
			// and object-boundary forces are computed with ODE
			if (OBJECT(info))
				computes_stuff = computes_stuff && (FLUID(neib_info) && !OBJECT(neib_info));

			// with SA_BOUNDARY, fluid and vertex particles interact with any
			// BOUNDARY particles in the neiblist, regardless of distance
			// TODO FIXME they should interact with BOUNDARY particles such
			// that the current particle influence radius intersects the
			// boundary element
			if (boundarytype == SA_BOUNDARY && (FLUID(info) || VERTEX(info)))
				computes_stuff = computes_stuff || BOUNDARY(neib_info);

			// bail out if we do not interact with this neighbor
			if (!computes_stuff)
				continue;

			// load rest of neib data
			forces_neib_data<kerneltype, sph_formulation, boundarytype, VISC_TYPE, DYNDT, USEXSPH> const
				ndata(pdata, params, neib_index, neib_info, relPos, r);

			/* Contributions from this neighbor */

			forces_neib_output<boundarytype> nout;

			/* Now compute the interactions based on info and neib_info */

			if (FLUID(info)) {
				if (FLUID(neib_info) || (boundarytype == SA_BOUNDARY && (BOUNDARY(neib_info) || VERTEX(neib_info)) ) ) {
					// compute DrDt and gamAS contributions
					if (boundarytype == SA_BOUNDARY && BOUNDARY(neib_info)) {
						pout.gGam.x += ndata.gamAS.x*ndata.belem.x;
						pout.gGam.y += ndata.gamAS.x*ndata.belem.y;
						pout.gGam.z += ndata.gamAS.x*ndata.belem.z;
						pout.gGam.w -= ndata.gamAS.y;
						nout.DrDt -= ndata.relVel.w*dot3(ndata.relVel, ndata.belem)*ndata.gamAS.x;
					} else if (boundarytype == SA_BOUNDARY && d_ferrari) {
						const float grav_corr = -dot(d_gravity, as_float3(ndata.relPos))*d_rho0[PART_FLUID_NUM(info)]/pdata.sqC0;
						float3 ferraricor = (ndata.r > 1e-4*params.slength) ? max(pdata.sspeed, ndata.sspeed)*(pdata.vel.w - ndata.relVel.w + grav_corr)/pdata.vel.w/ndata.r*as_float3(ndata.relPos) : make_float3(0.0);
						nout.DrDt = ndata.relPos.w*dot(as_float3(ndata.relVel) + d_ferrari*ferraricor, as_float3(ndata.relPos))*ndata.f;
					} else
						nout.DrDt = ndata.relPos.w*ndata.vel_dot_pos*ndata.f;
					/* The second formulation takes into consideration the density ratio */
					if (sph_formulation == SPH_F2)
						nout.DrDt *= pdata.vel.w/ndata.relVel.w;
					pout.force.w += nout.DrDt;

					// pressure part of acceleration (to be multiplied by neib_mass*f)
					switch (sph_formulation) {
						case SPH_F1:
							nout.DvDt = -(pdata.p_precalc + P(ndata.relVel.w, PART_FLUID_NUM(ndata.info))/(ndata.relVel.w*ndata.relVel.w));
							# ifdef VISC_KEPS
							nout.DvDt -= 2*ndata.keps_k/ndata.relVel.w/3.f;
							# endif
							break;
						case SPH_F2:
							nout.DvDt = -(pdata.p_precalc + P(ndata.relVel.w, PART_FLUID_NUM(ndata.info)))/(pdata.vel.w*ndata.relVel.w);
							break;
					}

					/* Viscous forces */
					const float visc(compute_visc<VISC_TYPE>()(params, pdata, ndata, pout, nout));
					if (VISC_TYPE != ARTVISC && !BOUNDARY(ndata.info))
						as_float3(pout.force) += visc*as_float3(ndata.relVel);

					# ifdef XSPH_KERNEL
					pout.mean_vel -= ndata.relPos.w*W<kerneltype>(ndata.r, params.slength)*as_float3(ndata.relVel)/(pdata.vel.w + ndata.relVel.w);
					# endif

					if (boundarytype == SA_BOUNDARY) {
						if (BOUNDARY(ndata.info)) {
							// pressure boundary term
							nout.bound_term_pres = nout.DvDt*ndata.relVel.w*ndata.gamAS.x*ndata.normal_s;

							// r_as - distance between fluid particle and boundary element along the normal
							float r_as = dot(as_float3(ndata.relPos), ndata.normal_s);
							if (r_as < params.deltap)
								r_as = params.deltap;

							// velocity of fluid particle along the wall
							const float3 vel_tau = as_float3(ndata.relVel) - dot(as_float3(ndata.relVel), ndata.normal_s)*ndata.normal_s;

							// These two expressions are correct only when used together with DYNAMICVISC or KEPSVISC model
							# ifdef VISC_KEPS
							// a component of fluid paricle velocity tangential to the wall
							const float3 u_t = as_float3(pdata.vel) - dot(as_float3(pdata.vel), ndata.normal_s)*ndata.normal_s;
							const float abs_u_t = length(u_t);
							float y_plus = params.deltap;

							// we solve iteratively the wall law equation to obtain y+ value
							float u_star = exp(-2.132f)*d_visccoeff/r_as;
							for (int i=0; i<10; i++) {
								y_plus = max(r_as*u_star/d_visccoeff, 11.f);
								u_star = (0.41f*abs_u_t + u_star)/(log(y_plus) + 2.132f + 1);
							}
							y_plus = max(r_as*u_star/d_visccoeff, 11.f);

							const float denom_term = pow(log(y_plus)/0.41f + 5.2f, 2);
							nout.bound_term_visc = 2*pdata.vel.w*abs_u_t*ndata.gamAS.x*u_t/denom_term;

							// velocity gradient
							const float3 rhoGGam = ndata.gamAS.x*ndata.normal_s*ndata.relVel.w;

							pout.dvx += ndata.relVel.x*rhoGGam;	// dvx = ∑ρs vxas ∇ɣas
							pout.dvy += ndata.relVel.y*rhoGGam;	// dvy = ∑ρs vyas ∇ɣas
							pout.dvz += ndata.relVel.z*rhoGGam;	// dvz = ∑ρs vzas ∇ɣas
							# else
							nout.bound_term_visc = ndata.gamAS.x*d_visccoeff*(pdata.vel.w + ndata.relVel.w)/r_as*vel_tau;
							# endif

							# ifdef VISC_KEPS
							//to be divided later by rho_a and gamma_a
							pout.diff_term_e += pow(0.09f, 0.75f)/0.41f * (
								pdata.dedt_precalc*pow(pdata.keps_k,1.5f)/(r_as*r_as) +
								ndata.relVel.w*(d_visccoeff + ndata.turbVisc/1.3f)*pow(ndata.keps_k,1.5f)/(params.deltap*params.deltap)) * ndata.gamAS.x;
							# endif

						}
						# ifdef VISC_KEPS
						else {
							//to be divided later by rho_a and gamma_a
							pout.diff_term_k += ndata.relPos.w*(
								pdata.dkdt_precalc + ndata.relVel.w*(d_visccoeff + ndata.turbVisc)
								)*(pdata.keps_k - ndata.keps_k)*ndata.f/ndata.relVel.w;
							pout.diff_term_e += ndata.relPos.w*(
								pdata.dedt_precalc + ndata.relVel.w*(d_visccoeff + ndata.turbVisc/1.3f)
								)*(pdata.keps_e - ndata.keps_e)*ndata.f/ndata.relVel.w;

							//velocity gradient
							pout.dvx -= ndata.relVel.x*as_float3(ndata.relPos)*ndata.f;	// dvx = -∑mb vxab (ra - rb)/r ∂Wab/∂r
							pout.dvy -= ndata.relVel.y*as_float3(ndata.relPos)*ndata.f;	// dvy = -∑mb vyab (ra - rb)/r ∂Wab/∂r
							pout.dvz -= ndata.relVel.z*as_float3(ndata.relPos)*ndata.f;	// dvz = -∑mb vzab (ra - rb)/r ∂Wab/∂r
						}
						# endif
					} // endif (boundarytype)

					nout.DvDt *= ndata.relPos.w*ndata.f;
				} else {
					switch (boundarytype) {
						case LJ_BOUNDARY:
							nout.DvDt = LJForce(ndata.r);
							break;
						case MK_BOUNDARY:
							nout.DvDt = MKForce(ndata.r, params.slength, pos.w, pos.w);
							break;
						case SA_BOUNDARY:
							// TODO FIXME this is currently encountered when the fluid interacts with a floating object
							nout.DvDt = LJForce(ndata.r);
							break;
						default:
							nout.DvDt = 1.0f/0.0f;
							break;
					}
				}
				if (boundarytype == SA_BOUNDARY && BOUNDARY(ndata.info)) {
					as_float3(pout.force) -= nout.bound_term_pres + nout.bound_term_visc/pdata.vel.w;
				} else {
					as_float3(pout.force) += nout.DvDt*as_float3(relPos);
				}
			}
			else if (boundarytype == SA_BOUNDARY && VERTEX(info)) {
				// we only get here if computeGamma || VISC_TYPE == KEPSVISC

				if (BOUNDARY(ndata.info)) {
					# ifdef VISC_KEPS
					// r_es - distance between vertex particle and boundary element along the normal
					float r_es = dot(as_float3(ndata.relPos), ndata.normal_s);
					if (r_es < params.deltap)
						r_es = params.deltap;
					#endif

					if (pdata.computeGamma){
						pout.gGam.x += ndata.gamAS.x*ndata.belem.x;
						pout.gGam.y += ndata.gamAS.x*ndata.belem.y;
						pout.gGam.z += ndata.gamAS.x*ndata.belem.z;
						pout.gGam.w -= ndata.gamAS.y;
					}

					# ifdef VISC_KEPS
					// velocity of vertex particle along the wall
					const float3 u_t = as_float3(pdata.vel) - dot(as_float3(pdata.vel), ndata.normal_s)*ndata.normal_s;
					const float abs_u_t = length(u_t);
					float y_plus = params.deltap;

					// we solve iteratively the wall law equation to obtain y+ value
					float u_star = exp(-2.132f)*d_visccoeff/r_es;
					for (int i=0; i<10; i++) {
						y_plus = max(r_es*u_star/d_visccoeff, 11.f);
						u_star = (0.41f*abs_u_t + u_star)/(log(y_plus) + 2.132f + 1);
					}
					y_plus = max(r_es*u_star/d_visccoeff, 11.f);

					const float denom_term = pow(log(y_plus)/0.41f + 5.2f, 2);

					pout.force.x -= 2*abs_u_t*ndata.gamAS.x*u_t.x/denom_term;
					pout.force.y -= 2*abs_u_t*ndata.gamAS.x*u_t.y/denom_term;
					pout.force.z -= 2*abs_u_t*ndata.gamAS.x*u_t.z/denom_term;
					#endif
				}
				# ifdef VISC_KEPS
				else {
					const float visc = laminarvisc_dynamic(pdata.vel.w, ndata.relVel.w, ndata.relPos.w, ndata.f, (d_visccoeff+pdata.turbVisc)*pdata.vel.w,
									(d_visccoeff+ndata.turbVisc)*ndata.relVel.w);

					pout.force.x += visc*ndata.relVel.x;
					pout.force.y += visc*ndata.relVel.y;
					pout.force.z += visc*ndata.relVel.z;
				} //end if BOUNDARY(neib_info)
				#endif
			}
			else if (OBJECT(info)) {
				nout.DvDt = ndata.relPos.w*LJForce(r);

				as_float3(pout.force) += nout.DvDt*as_float3(ndata.relPos);
			}
		} // end of loop over neighbors

		post_processor_t<kerneltype, sph_formulation, boundarytype,
			VISC_TYPE, DYNDT, USEXSPH> post_processor(index, pdata, pout, params);

		// External forces etc
		if (FLUID(info)) {
			# ifdef VISC_DYNAMIC
			const float dynvisc = d_visccoeff*pdata.vel.w;
			# elif defined(VISC_KINEMATIC) || defined(VISC_SPS)
			const float dynvisc = d_visccoeff*pdata.vel.w/4.0f;				// FIXME: check????????
			# elif defined(VISC_ARTVISC)
			const float dynvisc = 0.0f;
			# elif defined(VISC_KEPS)
			const float dynvisc = 0.0f;

			// velocity gradients
			pout.dvx /= pdata.vel.w * pout.gGam.w;	// dvx = -1/ɣa*ρa ∑mb vxab (ra - rb)/r ∂Wab/∂r
			pout.dvy /= pdata.vel.w * pout.gGam.w;	// dvy = -1/ɣa*ρa ∑mb vyab (ra - rb)/r ∂Wab/∂r
			pout.dvz /= pdata.vel.w * pout.gGam.w;	// dvz = -1/ɣa*ρa ∑mb vzab (ra - rb)/r ∂Wab/∂r
			// Calculate norm of the mean strain rate tensor
			float SijSij_bytwo = 2.0f*(pout.dvx.x*pout.dvx.x +
				pout.dvy.y*pout.dvy.y +
				pout.dvz.z*pout.dvz.z);	// 2*SijSij = 2.0((∂vx/∂x)^2 + (∂vy/∂yx)^2 + (∂vz/∂z)^2)
			float temp = pout.dvx.y + pout.dvy.x;
			SijSij_bytwo += temp*temp;		// 2*SijSij += (∂vx/∂y + ∂vy/∂x)^2
			temp = pout.dvx.z + pout.dvz.x;
			SijSij_bytwo += temp*temp;		// 2*SijSij += (∂vx/∂z + ∂vz/∂x)^2
			temp = pout.dvy.z + pout.dvz.y;
			SijSij_bytwo += temp*temp;		// 2*SijSij += (∂vy/∂z + ∂vz/∂y)^2
			float S = sqrtf(SijSij_bytwo);
			const float Pturb = pdata.turbVisc*S*S;					// production of turbulent kinetic energy (TKE)

			float dkdt = Pturb - pdata.keps_e + pout.diff_term_k/pdata.vel.w/pout.gGam.w;								// dk/dt
			float dedt = pdata.keps_e/pdata.keps_k*(1.44f*Pturb - 1.92f*pdata.keps_e) +
				pout.diff_term_e/pdata.vel.w/pout.gGam.w;	// de/dt

			params.keps_dkde[index].x = dkdt;
			params.keps_dkde[index].y = dedt;
			# else
			# error Unknown viscosity!
			# endif

			// only does something if SA_BOUNDARY
			post_processor.divideForceByGamma();

			// Adding gravity
			as_float3(pout.force) += d_gravity;

			// TODO: check for time step limitation in case of geometrical boundaries (DEM or planes)
			// for viscous fluids
			float geom_coeff = 0.0f;

			// Adding repulsive force computed from DEM
			if (usedem) {
				switch (boundarytype) {
					case LJ_BOUNDARY:
						geom_coeff = DemLJForce(demTex,
							as_float3(pdata.pos) + pdata.gridPos*d_cellSize + 0.5f*d_cellSize,
										pdata.pos.w, as_float3(pdata.vel), dynvisc, pout.force);
						break;
					default:
						break;
				}
			}

			// Adding repulsive force computed from geometric boundaries
			if (d_numplanes) {
				geom_coeff = max(geom_coeff,
					GeometryForce(d_worldOrigin + as_float3(pdata.pos) + pdata.gridPos*d_cellSize + 0.5f*d_cellSize,
							pdata.pos.w, as_float3(pdata.vel), dynvisc, pout.force));
			}

			# ifdef DT_KERNEL
			// storing data for cfl condition in shared memory
			sm_max[threadIdx.x] = max(length(as_float3(pout.force)), pdata.sspeed*pdata.sspeed/params.slength);
			# ifdef VISC_KEPS
			sm_max_nut[threadIdx.x] = pdata.turbVisc;
			# endif
			# endif
		}
		else if (VERTEX(info)) {
			post_processor.divideForceByGamma();
		}

		// Writing out the results
		if (!OBJECT(info)) {
			post_processor.write_forces();
			post_processor.write_gamma();
		}

		if (FLUID(info)) {
			post_processor.write_xsph();

			# ifdef VISC_KEPS
			post_processor.write_turbvisc();
			# endif
		}

		if (OBJECT(info)) {
			params.rbforces[pdata.rbindex] = pout.force;
			params.rbtorques[pdata.rbindex] = make_float4(
				cross(d_worldOrigin + as_float3(pdata.pos) + pdata.gridPos*d_cellSize + 0.5f*d_cellSize
								- d_rbcg[object(info)], as_float3(pout.force)));
		}

	} while (0);

	# ifdef DT_KERNEL
	dtadaptBlockReduce(sm_max, params.cfl);
	# ifdef VISC_KEPS
	dtadaptBlockReduce(sm_max_nut, params.cfltvisc);
	# endif
	# endif
}
/************************************************************************************************************/

#undef FORCES_CUDA_KERNEL

/* vi:set ft=cuda: */
