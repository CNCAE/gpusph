/*  Copyright 2011 Alexis Herault, Giuseppe Bilotta, Robert A. Dalrymple, Eugenio Rustico, Ciro Del Negro

	Istituto de Nazionale di Geofisica e Vulcanologia
          Sezione di Catania, Catania, Italy

    Universita di Catania, Catania, Italy

    Johns Hopkins University, Baltimore, MD

    This file is part of GPUSPH.

    GPUSPH is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    GPUSPH is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with GPUSPH.  If not, see <http://www.gnu.org/licenses/>.
*/

/* Euler kernel definitions */
// Predictor Corrector time integration
// - for step 1:
//	  v(n+1/2) = v(n) + f(n)*dt/2
//	  pos(n+1/2) = pos(n) + v(n)*dt/2
//
//	  We have oldVel = v(n), oldPos = pos(n), forces = f(n) so
//	  newVel = v(n+1/2) = oldVel + forces*dt/2
//	  newPos = pos(n+1/2) = oldPos + oldVel*dt/2
//
// - for step 2:
//	  vc(n+1/2) = v(n) + f(n+1/2)*dt/2
//	  posc(n+1/2) = pos(n) + vc(n+1/2)*dt/2
//	  then:
//	  v(n+1) = 2vc(n+1/2) - v(n) = v(n) + f(n+1/2)*dt
//	  pos(n+1) = 2posc(n+1/2) - pos(n) = pos(n) + vc(n+1/2)*dt
//
//	  Whe have oldVel = v(n), oldPos = pos(n), force = f(n+1/2),
//	  newVel = vel(n+1/2), newPos = pos(n+1/2) so
//	  we store velc = v(n) + f(n+1/2)*dt/2 then
//	  newPos = pos(n+1) = oldPos + velc*dt
//	  newVel = vel(n+1) = oldVel + forces*dt;

// Remember that for step 1 dt => dt/2 and for step 2 dt => dt !!!
// but dt2 is always equal to dt/2

// WARNING: in first step, NULL is passed in place of newNumParts!

template<int step, int periodicbound>
__global__ void
EULER_KERNEL_NAME(
	const	float4	*oldPos,
	const	float4	*oldVel,
	particleinfo	*info,
	const	float4	*forces,
#if XSPH_KERNEL
	const	float4	*xsph,
#endif
			float4	*newPos,
			float4	*newVel,
			uint	*newNumParts,
			uint	numParticles,
			// TODO make it a const instead?
			uint	maxParticles,
			float	dt,
			float	dt2,
			float	t)
{
	int index = INTMUL(blockIdx.x,blockDim.x) + threadIdx.x;

	if (index >= numParticles)
		return;

	// read particle data from sorted arrays
	// Euler does nothing to boundary particles apart
	// copying pos and vel in the new arrays
	float4 pos = oldPos[index];		// always pos(n)
	float4 vel = oldVel[index];		// always vel(n)

	/* Since we never use the last two components of pinfo, the compiler is
	   ‘smart’ enough to not load them at all. This kills coalescence on
	   older hardware, because each thread reads 32 bits, with a 32-bit gap
	   between one thread and the next.
	   We can work around this by forcing the compiler to code a read for
	   a 64-bit word by reading a long int at our interested address,
	   and then casting the result to particleinfo.
	   This speeds up the euler kernel by 20% on 1.1 devices, and by
	   only doing it for older hardware we spare ourselves the very small
	   performance loss that we'd find on 2.0 devices with the hack. */
	#if __GPU_ARCH__ < 200
	long int hack = *reinterpret_cast<long int*>(info + index);
	particleinfo pinfo = *reinterpret_cast<particleinfo*>(&hack);
	#else
	particleinfo pinfo = info[index];
	#endif

	if(type(pinfo) != BOUNDPART) {
		float4 force = forces[index];	// f(n) at step 1 and f(n+1/2) at step 2
		# ifdef XSPH_KERNEL
		float4 mean_vel = xsph[index];
		# endif
		/*
		   velc = vel if step == 1, but
		   velc = vel + forces[index]*dt/2.0f if step == 2
		 */
		float4 velc = vel + (step - 1)*forces[index]*dt2;

		// Updating particle position
		if (FLUID(pinfo) && ACTIVE(pos)) {
			// check to see if the particle is in an outlet
			int outlet = find_outlet(pos);

			// which inlent is the particle in?
			int inlet = -1;
			// is the particle in the first half of the inlet?
			bool half_inlet = false;
			if (outlet < 0) {
				// if the particle is NOT inside an outlet, check if it's in an inlet
				inlet = find_inlet(pos);
			} else {
				// otherwise, freeze the velocity parallel to the outlet direction
				if (d_outlet_disp[outlet].x != 0) {
					force.x = 0;
				}
				if (d_outlet_disp[outlet].y != 0) {
					force.y = 0;
				}
				if (d_outlet_disp[outlet].z != 0) {
					force.z = 0;
				}
			}

			// if the fluid particle is in an inlet, its motion is prescribed
			// by the corresponding fixed velocity
			if (inlet >= 0) {
				// if pos - disp is inside the inlet, we are in the first
				// half of the inlet
				half_inlet = inside_inlet(inlet, pos - d_inlet_disp[inlet]);

				// (inverse) weights for the influence of the fields - linear from low to high coords
				float weight_x = 0.0F;
				float weight_y = 0.0F;
				float weight_z = 0.0F;
				float weight_w = 0.0F;
				// are we in the second half? Then fade the effect of the field (0 when the field is strong, 1 where it's null)
				if (!half_inlet) {
					weight_x = weight_y = weight_z = weight_w =
							(pos.y - d_inlet_min[inlet].y + d_inlet_disp[inlet].y) / (- d_inlet_disp[inlet].y);
				}

				// it is possible to only prescribe specific
				// components in a velocity field, by setting the other
				// components to NaN: the non-prescribed components
				// will be left to evole naturally
				if (isfinite(d_inlet_vel[inlet].x)) {
					vel.x = weight_x * vel.x + (1-weight_x) * d_inlet_vel[inlet].x;
					velc.x = weight_x * velc.x + (1-weight_x) * d_inlet_vel[inlet].x;
					force.x *= weight_x;
				}
				if (isfinite(d_inlet_vel[inlet].y)) {
					vel.y = weight_y * vel.y + (1-weight_y) * d_inlet_vel[inlet].y;
					velc.y = weight_y * velc.y + (1-weight_y) * d_inlet_vel[inlet].y;
					force.y *= weight_y;
				}
				if (isfinite(d_inlet_vel[inlet].z)) {
					vel.z = weight_z * vel.z + (1-weight_z) * d_inlet_vel[inlet].z;
					velc.z = weight_z * velc.z + (1-weight_z) * d_inlet_vel[inlet].z;
					force.z *= weight_z;
				}
				if (isfinite(d_inlet_vel[inlet].w)) {
					vel.w = weight_w * vel.w + (1-weight_w) * d_inlet_vel[inlet].w;
					velc.w = weight_w * velc.w + (1-weight_w) * d_inlet_vel[inlet].w;
					force.w *= weight_w;
				}
				# ifdef XSPH_KERNEL
				mean_vel.x = mean_vel.y = mean_vel.z = 0;
				# endif
			}

			// new position is given by pos + pos_corr, with pos_corr given by
			// velc [ + optional xsph correction ] * dt
			float3 pos_corr = as_float3(velc);
			# ifdef XSPH_KERNEL
			pos_corr += d_epsxsph*as_float3(mean_vel);
			# endif
			pos_corr *= dt;

#if 0
			// check if particle would get inside an inlet, and if it happens,
			// push it out
			// TODO: find a smarter way to handle this case
			int new_inlet = find_inlet(pos+pos_corr);
			if (inlet < 0 && new_inlet >= 0) {
				pos_corr = -pos_corr;
				vel.x = -vel.x;
				vel.y = -vel.y;
				vel.z = -vel.z;
			}
#endif

			pos.x += pos_corr.x;
			pos.y += pos_corr.y;
			pos.z += pos_corr.z;

			// Updating particle velocity
			// For step 1:
			//	  vel = vel(n+1/2) = vel(n) + f(n)*dt/2
			// For step 2:
			//	  vel = vel(n+1) = vel(n) + f(n+1/2)*dt
			vel += dt*force;

			// if the particle was inside an outlet, and it got out
			// in the correct direction, disable it. Otherwise, if it
			// was in the first half of an inlet and it got out (of that
			// half), replicate it at the beginning of the inlet
			// (on the second integration step only)
			if (outlet >= 0	&& !inside_outlet(outlet, pos)
							&& dot(pos_corr, as_float3(d_outlet_disp[outlet])) > 0) {
				disable_particle(pos);
			} else if ((step == 2) && half_inlet) {
				// the new particle is to be created only if its potential
				// new position clone_pos would be inside the inlet
				float4 clone_pos = pos + d_inlet_disp[inlet];
				if (inside_inlet(inlet, clone_pos)) {
					// create a new particle
					float4 clone_vel = vel;
					particleinfo clone_info = pinfo;

					// TODO of course make_particleinfo doesn't work on GPU due to the memcpy(),
					// so we need a GPU-safe way to do this. The current code is little-endian
					// only, so it's bound to break on other archs. I'm seriously starting to think
					// that we can drop the stupid particleinfo ushort4 typedef and we should just
					// define particleinfo as a ushort ushort uint struct, with proper alignment.
					// FIXME endianness
					uint clone_id = id(pinfo) + maxParticles;
					clone_info.z = (clone_id & 0xffff);
					clone_info.w = ((clone_id >> 16) & 0xffff);

					// TODO optimize by having only one thread calling atomicAdd,
					// adding enough for all threads in the block
					int clone_idx = atomicAdd(newNumParts, 1);
					if (clone_idx < maxParticles) {
						newPos[clone_idx] = clone_pos;
						newVel[clone_idx] = clone_vel;
						info[clone_idx] = clone_info;
					}
				}
			}

		}
		// Updating postions for Piston particles
		else if (type(pinfo) == PISTONPART) {
			const int i = object(pinfo);
			pos.x = d_mbdata[i].x;
		}
		// Updating postions for Paddle particles
		else if (type(pinfo)  == PADDLEPART) {
			const int i = object(pinfo);
			const float r = length(make_float2(pos.x - d_mbdata[i].x, pos.z - d_mbdata[i].y));
			pos.x = d_mbdata[i].x + r*d_mbdata[i].z;	// r*sin(theta(t))
			pos.z = d_mbdata[i].y + r*d_mbdata[i].w;	// r*cos(theta(t))
		}
		// Updating postions for Gate particles
		// At each substep the gate part covers a distance equals to v*dt/2.0
		// so in 2 substep the gate covers v*dt BUT pos is always pos(n) so
		// at step 1 we have pos += v*dt with dt=dt/2 and at step 2 we have
		// pos += v*dt with dt = dt
		else if (type(pinfo)  == GATEPART) {
			const int i = object(pinfo);
			pos.x += d_mbdata[i].x*dt;
			pos.y += d_mbdata[i].y*dt;
			pos.z += d_mbdata[i].z*dt;
		}
		// TODO: test rotations
		else if (type(pinfo) == OBJECTPART) {
			const int i = object(pinfo);

			// Applying rotation around center of gravity
			applyrot(&d_rbsteprot[9*i], pos, d_rbcg[i]);

			// Applying center of gravity translation
			pos.x += d_rbtrans[i].x;
			pos.y += d_rbtrans[i].y;
			pos.z += d_rbtrans[i].z;
		}

		if (periodicbound) {
			if (d_dispvect.x) {
				if (pos.x >= d_maxlimit.x) {
					pos.x -= d_dispvect.x;
					pos.y -= d_dispOffset.y;
					pos.z -= d_dispOffset.z;
				} else if (pos.x < d_minlimit.x) {
					pos.x += d_dispvect.x;
					pos.y += d_dispOffset.y;
					pos.z += d_dispOffset.z;
				}
			}
			if (d_dispvect.y) {
				if (pos.y >= d_maxlimit.y) {
					pos.y -= d_dispvect.y;
					pos.x -= d_dispOffset.x;
					pos.z -= d_dispOffset.z;
				} else if (pos.y < d_minlimit.y) {
					pos.y += d_dispvect.y;
					pos.x += d_dispOffset.x;
					pos.z += d_dispOffset.z;
				}
			}
			if (d_dispvect.z) {
				if (pos.z >= d_maxlimit.z) {
					pos.z -= d_dispvect.z;
					pos.x -= d_dispOffset.x;
					pos.y -= d_dispOffset.y;
				} else if (pos.z < d_minlimit.z) {
					pos.z += d_dispvect.z;
					pos.x += d_dispOffset.x;
					pos.y += d_dispOffset.y;
				}
			}
		}
	}

	newPos[index] = pos;
	newVel[index] = vel;
}

/* vi:set ft=cuda: */
